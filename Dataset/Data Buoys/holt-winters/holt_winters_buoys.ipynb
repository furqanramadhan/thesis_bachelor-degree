{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cleaned_data(location_code, file_path):\n",
    "    \"\"\"\n",
    "    Load cleaned data with proper frequency handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Error: File not found at {file_path}\")\n",
    "            return None\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df = df.sort_index().asfreq('D')  # Force daily frequency\n",
    "        \n",
    "        # Forward fill missing values (adjust based on data nature)\n",
    "        df = df.ffill().bfill()  # Simple handling for demonstration\n",
    "        \n",
    "        print(f\"Data loaded successfully for {location_code} (Frequency: {df.index.freq})\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for {location_code}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hw_model(data: pd.DataFrame, variable: str, seasonal_periods: int = 365, train_ratio: float = 0.8):\n",
    "    \"\"\"\n",
    "    Train Holt-Winters model with improved initialization and error handling.\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise TypeError(\"data must be a pandas DataFrame\")\n",
    "    if variable not in data.columns:\n",
    "        raise ValueError(f\"Variable '{variable}' not found in data\")\n",
    "    if not 0 < train_ratio < 1:\n",
    "        raise ValueError(\"train_ratio must be between 0 and 1\")\n",
    "\n",
    "    # Clean and prepare data\n",
    "    data_cleaned = data[[variable]].dropna().copy()\n",
    "    if len(data_cleaned) < 2:\n",
    "        raise ValueError(\"Insufficient data after cleaning\")\n",
    "\n",
    "    # Check seasonal period length\n",
    "    if len(data_cleaned) < 2 * seasonal_periods:\n",
    "        print(f\"Warning: Data length ({len(data_cleaned)}) is less than 2 complete seasonal cycles ({2*seasonal_periods})\")\n",
    "        seasonal_periods = None\n",
    "\n",
    "    # Split data\n",
    "    train_size = int(len(data_cleaned) * train_ratio)\n",
    "    train_data = data_cleaned.iloc[:train_size]\n",
    "    test_data = data_cleaned.iloc[train_size:]\n",
    "\n",
    "    # Configure model with use_boxcox at initialization\n",
    "    model = ExponentialSmoothing(\n",
    "        train_data[variable],\n",
    "        trend='add',\n",
    "        seasonal='add' if seasonal_periods else None,\n",
    "        seasonal_periods=seasonal_periods,\n",
    "        damped_trend=True,\n",
    "        initialization_method=\"estimated\",\n",
    "        use_boxcox=False  # Moved here from fit()\n",
    "    )\n",
    "\n",
    "    # Fit model with optimized parameters\n",
    "    try:\n",
    "        # Fix: Properly specify optimization bounds directly in fit() \n",
    "        # instead of using minimize_kwargs with bounds\n",
    "        model_fit = model.fit(\n",
    "            optimized=True,\n",
    "            remove_bias=True,\n",
    "            method='L-BFGS-B',\n",
    "            smoothing_level=0.2,  # Starting values\n",
    "            smoothing_trend=0.05,\n",
    "            smoothing_seasonal=0.15 if seasonal_periods else None,\n",
    "            damping_trend=0.95,\n",
    "            start_params=None,  # Let the model determine starting parameters\n",
    "            bounds={\n",
    "                'smoothing_level': (0, 1),\n",
    "                'smoothing_trend': (0, 1),\n",
    "                'smoothing_seasonal': (0, 1),\n",
    "                'damping_trend': (0.8, 0.98)\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Optimization failed, using default parameters. Error: {e}\")\n",
    "        # Fallback to default parameters\n",
    "        model_fit = model.fit(\n",
    "            smoothing_level=0.2,\n",
    "            smoothing_trend=0.05,\n",
    "            smoothing_seasonal=0.15 if seasonal_periods else None,\n",
    "            damping_trend=0.98,\n",
    "            optimized=False\n",
    "        )\n",
    "\n",
    "    print(f\"Model fitted successfully. Training size: {len(train_data)}, Test size: {len(test_data)}\")\n",
    "    return model_fit, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_fit, test_data, variable):\n",
    "    \"\"\"\n",
    "    Evaluate model with index alignment.\n",
    "    \"\"\"\n",
    "    forecast_horizon = len(test_data)\n",
    "    \n",
    "    # Generate index-aligned forecast\n",
    "    forecast = model_fit.forecast(forecast_horizon)\n",
    "    forecast = pd.Series(forecast, index=test_data.index)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(test_data[variable], forecast)\n",
    "    rmse = np.sqrt(mean_squared_error(test_data[variable], forecast))\n",
    "    mape = np.mean(np.abs((test_data[variable] - forecast) / test_data[variable])) * 100\n",
    "    \n",
    "    print(f\"Evaluation metrics for {variable}:\")\n",
    "    print(f\"MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    return {'mae': mae, 'rmse': rmse, 'mape': mape}, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecasts(train_data, test_data, forecast, variable, location_code, output_dir):\n",
    "    \"\"\"\n",
    "    Plot the forecasts against actual data.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    \n",
    "    # Handle different index types\n",
    "    if isinstance(train_data.index, pd.DatetimeIndex):\n",
    "        x_train = train_data.index\n",
    "        x_test = test_data.index\n",
    "        x_forecast = forecast.index if hasattr(forecast, 'index') else test_data.index\n",
    "    else:\n",
    "        # Create arbitrary dates for plotting\n",
    "        x_train = np.arange(len(train_data))\n",
    "        x_test = np.arange(len(train_data), len(train_data) + len(test_data))\n",
    "        x_forecast = x_test\n",
    "    \n",
    "    # Plot data\n",
    "    plt.plot(x_train, train_data[variable], label='Training Data')\n",
    "    plt.plot(x_test, test_data[variable], label='Test Data')\n",
    "    plt.plot(x_forecast, forecast, label='Forecast', color='red')\n",
    "    \n",
    "    plt.title(f'{variable} Forecast for {location_code}')\n",
    "    plt.xlabel('Date')\n",
    "    \n",
    "    if variable == 'SST':\n",
    "        plt.ylabel('Sea Surface Temperature (°C)')\n",
    "    elif variable == 'SWRad':\n",
    "        plt.ylabel('Shortwave Radiation (W/m²)')\n",
    "    elif variable == 'WSPD':\n",
    "        plt.ylabel('Wind Speed (m/s)')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save figure\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, f'{location_code}_{variable}_forecast.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_thresholds():\n",
    "    \"\"\"\n",
    "    Define thresholds for each variable for rice planting suitability.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Thresholds for each variable\n",
    "    \"\"\"\n",
    "    # These thresholds should be adjusted based on research and local conditions\n",
    "    thresholds = {\n",
    "        'SST': {\n",
    "            'min': 27.0,  # Minimum SST in °C for favorable conditions\n",
    "            'max': 30.0,  # Maximum SST in °C for favorable conditions\n",
    "            'weight': 0.3  # Relative importance weight\n",
    "        },\n",
    "        'SWRad': {\n",
    "            'min': 150.0,  # Minimum radiation in W/m² for adequate photosynthesis\n",
    "            'max': None,   # No upper limit for radiation (more is generally better)\n",
    "            'weight': 0.4  # Relative importance weight\n",
    "        },\n",
    "        'WSPD': {\n",
    "            'min': 1.0,    # Minimum wind speed in m/s (too little means stagnant air)\n",
    "            'max': 6.0,    # Maximum wind speed in m/s (too much can damage plants)\n",
    "            'weight': 0.3  # Relative importance weight\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_monthly_suitability(forecasts, thresholds):\n",
    "    \"\"\"\n",
    "    Calculate monthly suitability scores based on forecasted variables.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    forecasts : dict\n",
    "        Dictionary with forecasted values for each variable\n",
    "    thresholds : dict\n",
    "        Thresholds for each variable\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Monthly suitability scores and decisions\n",
    "    \"\"\"\n",
    "    # Create a DataFrame with forecasted values\n",
    "    forecast_df = pd.DataFrame()\n",
    "    \n",
    "    # Add each variable's forecast to the DataFrame\n",
    "    for var, values in forecasts.items():\n",
    "        forecast_df[var] = values\n",
    "    \n",
    "    # Resample to monthly averages\n",
    "    monthly_df = forecast_df.resample('MS').mean()\n",
    "    \n",
    "    # Initialize suitability scores\n",
    "    monthly_df['SST_suitable'] = 0.0\n",
    "    monthly_df['SWRad_suitable'] = 0.0\n",
    "    monthly_df['WSPD_suitable'] = 0.0\n",
    "    \n",
    "    # Calculate suitability scores for each variable\n",
    "    for var in ['SST', 'SWRad', 'WSPD']:\n",
    "        if var in monthly_df.columns:\n",
    "            # Check minimum threshold\n",
    "            if thresholds[var]['min'] is not None:\n",
    "                monthly_df[f'{var}_suitable'] = np.where(\n",
    "                    monthly_df[var] >= thresholds[var]['min'],\n",
    "                    monthly_df[f'{var}_suitable'] + 0.5,\n",
    "                    monthly_df[f'{var}_suitable']\n",
    "                )\n",
    "            \n",
    "            # Check maximum threshold\n",
    "            if thresholds[var]['max'] is not None:\n",
    "                monthly_df[f'{var}_suitable'] = np.where(\n",
    "                    monthly_df[var] <= thresholds[var]['max'],\n",
    "                    monthly_df[f'{var}_suitable'] + 0.5,\n",
    "                    monthly_df[f'{var}_suitable']\n",
    "                )\n",
    "    \n",
    "    # Calculate weighted overall suitability\n",
    "    monthly_df['overall_suitability'] = (\n",
    "        monthly_df['SST_suitable'] * thresholds['SST']['weight'] +\n",
    "        monthly_df['SWRad_suitable'] * thresholds['SWRad']['weight'] +\n",
    "        monthly_df['WSPD_suitable'] * thresholds['WSPD']['weight']\n",
    "    )\n",
    "    \n",
    "    # Normalize overall suitability to 0-1 range\n",
    "    max_possible = (\n",
    "        1.0 * thresholds['SST']['weight'] +\n",
    "        1.0 * thresholds['SWRad']['weight'] +\n",
    "        1.0 * thresholds['WSPD']['weight']\n",
    "    )\n",
    "    monthly_df['overall_suitability'] = monthly_df['overall_suitability'] / max_possible\n",
    "    \n",
    "    return monthly_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_planting_decisions(monthly_suitability, suitability_threshold=0.7, grow_days=95):\n",
    "    \"\"\"\n",
    "    Make rice planting decisions based on suitability scores.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    monthly_suitability : DataFrame\n",
    "        Monthly suitability scores\n",
    "    suitability_threshold : float\n",
    "        Minimum suitability score to recommend planting (0-1)\n",
    "    grow_days : int\n",
    "        Number of days required for rice to grow and be harvested\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Monthly planting decisions\n",
    "    \"\"\"\n",
    "    # Create copy to avoid modifying original\n",
    "    decision_df = monthly_suitability.copy()\n",
    "    \n",
    "    # Initialize decisions\n",
    "    decision_df['decision'] = 'Tidak Sesuai'  # Default to \"Not Suitable\"\n",
    "    \n",
    "    # Mark suitable months for planting\n",
    "    decision_df.loc[decision_df['overall_suitability'] >= suitability_threshold, 'decision'] = 'Sesuai'\n",
    "    \n",
    "    # Convert to list for easier processing\n",
    "    months = decision_df.index.tolist()\n",
    "    decisions = decision_df['decision'].tolist()\n",
    "    \n",
    "    # Account for growth period (harvesting after grow_days)\n",
    "    # Assume approximately 3 months for rice growth\n",
    "    grow_months = grow_days // 30\n",
    "    \n",
    "    final_decisions = []\n",
    "    for i in range(len(decisions)):\n",
    "        if decisions[i] == 'Sesuai':\n",
    "            # Check future months for harvesting suitability\n",
    "            if i + grow_months < len(decisions):\n",
    "                if decisions[i + grow_months] == 'Sesuai':\n",
    "                    final_decisions.append('Tanam')  # Plant\n",
    "                else:\n",
    "                    final_decisions.append('Tidak Sesuai')  # Not suitable due to harvest conditions\n",
    "            else:\n",
    "                final_decisions.append('Tidak Sesuai')  # Not enough time in forecast for full growing cycle\n",
    "        else:\n",
    "            # Check if this is a harvest month for a previous planting\n",
    "            is_harvest_month = False\n",
    "            for j in range(1, grow_months + 1):\n",
    "                if i - j >= 0 and final_decisions[i - j] == 'Tanam':\n",
    "                    is_harvest_month = True\n",
    "                    break\n",
    "            \n",
    "            if is_harvest_month:\n",
    "                final_decisions.append('Panen')  # Harvest\n",
    "            else:\n",
    "                final_decisions.append('Bera')  # Fallow\n",
    "    \n",
    "    # Add final decisions to DataFrame\n",
    "    decision_df['final_decision'] = final_decisions\n",
    "    \n",
    "    return decision_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_planting_calendar(decision_df, location_code, output_dir):\n",
    "    \"\"\"\n",
    "    Generate planting calendar visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    decision_df : DataFrame\n",
    "        Monthly planting decisions\n",
    "    location_code : str\n",
    "        Location identifier\n",
    "    output_dir : str\n",
    "        Directory for saving outputs\n",
    "    \"\"\"\n",
    "    # Prepare data for plotting\n",
    "    months = decision_df.index.strftime('%Y-%m')\n",
    "    decisions = decision_df['final_decision']\n",
    "    \n",
    "    # Define colors for different decisions\n",
    "    colors = {\n",
    "        'Tanam': 'green',\n",
    "        'Panen': 'gold',\n",
    "        'Bera': 'brown',\n",
    "        'Tidak Sesuai': 'red'\n",
    "    }\n",
    "    \n",
    "    # Map decisions to colors\n",
    "    bar_colors = [colors[d] for d in decisions]\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Plot horizontal bars\n",
    "    y_pos = np.arange(len(months))\n",
    "    plt.barh(y_pos, 1, color=bar_colors)\n",
    "    \n",
    "    # Add labels\n",
    "    plt.yticks(y_pos, months)\n",
    "    plt.xlabel('Decision')\n",
    "    plt.title(f'Rice Planting Calendar for {location_code}')\n",
    "    \n",
    "    # Add legend\n",
    "    for decision, color in colors.items():\n",
    "        plt.bar(0, 0, color=color, label=decision)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    # Save figure\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, f'{location_code}_planting_calendar.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Also save as CSV\n",
    "    decision_df.to_csv(os.path.join(output_dir, f'{location_code}_planting_calendar.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_monthly_decisions(decision_df, location_code, output_dir):\n",
    "    \"\"\"\n",
    "    Export monthly decisions in a simple format.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    decision_df : DataFrame\n",
    "        Monthly planting decisions\n",
    "    location_code : str\n",
    "        Location identifier\n",
    "    output_dir : str\n",
    "        Directory for saving outputs\n",
    "    \"\"\"\n",
    "    # Format for export\n",
    "    export_df = decision_df.copy()\n",
    "    export_df.index = export_df.index.strftime('%Y-%m')\n",
    "    \n",
    "    # Keep only essential columns\n",
    "    export_df = export_df[['overall_suitability', 'final_decision']]\n",
    "    \n",
    "    # Export to CSV\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    export_path = os.path.join(output_dir, f'{location_code}_monthly_decisions.csv')\n",
    "    export_df.to_csv(export_path)\n",
    "    \n",
    "    print(f\"Exported monthly decisions to {export_path}\")\n",
    "    \n",
    "    # Create a simplified text version\n",
    "    with open(os.path.join(output_dir, f'{location_code}_decisions.txt'), 'w') as f:\n",
    "        f.write(';'.join([d for d in export_df['final_decision']]))\n",
    "    \n",
    "    return export_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing location: 0N90E\n",
      "==================================================\n",
      "Data loaded successfully for 0N90E (Frequency: <Day>)\n",
      "\n",
      "Forecasting SST for 0N90E\n",
      "Optimization failed, using default parameters. Error: ExponentialSmoothing.fit() got an unexpected keyword argument 'bounds'\n",
      "Model fitted successfully. Training size: 4509, Test size: 1128\n",
      "Evaluation metrics for SST:\n",
      "MAE: 0.96, RMSE: 1.05, MAPE: 3.26%\n",
      "\n",
      "Forecasting SWRad for 0N90E\n",
      "Optimization failed, using default parameters. Error: ExponentialSmoothing.fit() got an unexpected keyword argument 'bounds'\n",
      "Model fitted successfully. Training size: 4509, Test size: 1128\n",
      "Evaluation metrics for SWRad:\n",
      "MAE: 102.32, RMSE: 111.15, MAPE: 50.02%\n",
      "\n",
      "Forecasting WSPD for 0N90E\n",
      "Optimization failed, using default parameters. Error: ExponentialSmoothing.fit() got an unexpected keyword argument 'bounds'\n",
      "Model fitted successfully. Training size: 4509, Test size: 1128\n",
      "Evaluation metrics for WSPD:\n",
      "MAE: 4.63, RMSE: 5.16, MAPE: 131.08%\n",
      "Exported monthly decisions to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Data Buoys/results/0N90E_monthly_decisions.csv\n",
      "\n",
      "Completed processing for 0N90E\n",
      "\n",
      "==================================================\n",
      "Processing location: 4N90E\n",
      "==================================================\n",
      "Data loaded successfully for 4N90E (Frequency: <Day>)\n",
      "\n",
      "Forecasting SST for 4N90E\n",
      "Optimization failed, using default parameters. Error: ExponentialSmoothing.fit() got an unexpected keyword argument 'bounds'\n",
      "Model fitted successfully. Training size: 3420, Test size: 856\n",
      "Evaluation metrics for SST:\n",
      "MAE: 1.33, RMSE: 1.40, MAPE: 4.52%\n",
      "\n",
      "Forecasting SWRad for 4N90E\n",
      "Optimization failed, using default parameters. Error: ExponentialSmoothing.fit() got an unexpected keyword argument 'bounds'\n",
      "Model fitted successfully. Training size: 3420, Test size: 856\n",
      "Evaluation metrics for SWRad:\n",
      "MAE: 207.21, RMSE: 213.70, MAPE: 97.82%\n",
      "\n",
      "Forecasting WSPD for 4N90E\n",
      "Optimization failed, using default parameters. Error: ExponentialSmoothing.fit() got an unexpected keyword argument 'bounds'\n",
      "Model fitted successfully. Training size: 3420, Test size: 856\n",
      "Evaluation metrics for WSPD:\n",
      "MAE: 0.97, RMSE: 1.19, MAPE: 21.53%\n",
      "Exported monthly decisions to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Data Buoys/results/4N90E_monthly_decisions.csv\n",
      "\n",
      "Completed processing for 4N90E\n",
      "\n",
      "==================================================\n",
      "Processing location: 8N90E\n",
      "==================================================\n",
      "Data loaded successfully for 8N90E (Frequency: <Day>)\n",
      "\n",
      "Forecasting SST for 8N90E\n",
      "Optimization failed, using default parameters. Error: ExponentialSmoothing.fit() got an unexpected keyword argument 'bounds'\n",
      "Model fitted successfully. Training size: 3878, Test size: 970\n",
      "Evaluation metrics for SST:\n",
      "MAE: 0.30, RMSE: 0.40, MAPE: 1.02%\n",
      "\n",
      "Forecasting SWRad for 8N90E\n",
      "Optimization failed, using default parameters. Error: ExponentialSmoothing.fit() got an unexpected keyword argument 'bounds'\n",
      "Model fitted successfully. Training size: 3878, Test size: 970\n",
      "Evaluation metrics for SWRad:\n",
      "MAE: 55.90, RMSE: 79.25, MAPE: 33.64%\n",
      "\n",
      "Forecasting WSPD for 8N90E\n",
      "Optimization failed, using default parameters. Error: ExponentialSmoothing.fit() got an unexpected keyword argument 'bounds'\n",
      "Model fitted successfully. Training size: 3878, Test size: 970\n",
      "Evaluation metrics for WSPD:\n",
      "MAE: 4.19, RMSE: 4.93, MAPE: inf%\n",
      "Exported monthly decisions to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Data Buoys/results/8N90E_monthly_decisions.csv\n",
      "\n",
      "Completed processing for 8N90E\n",
      "\n",
      "All locations processed successfully!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function for rice planting decision support system.\n",
    "    \"\"\"\n",
    "    # Define location codes and directories\n",
    "    location_codes = ['0N90E', '4N90E', '8N90E']\n",
    "    data_dirs = {\n",
    "        '0N90E': '/run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Data Buoys/0N90E/CSV CLEANED/0N90E_combined_clean.csv',\n",
    "        '4N90E': '/run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Data Buoys/4N90E/CSV CLEANED/4N90E_combined_clean.csv',\n",
    "        '8N90E': '/run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Data Buoys/8N90E/CSV CLEANED/8N90E_combined_clean.csv'\n",
    "    }\n",
    "    output_dir = '/run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Data Buoys/results'\n",
    "\n",
    "    # Process each location\n",
    "    for location_code in location_codes:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing location: {location_code}\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        file_path = data_dirs.get(location_code)\n",
    "        if not file_path or not os.path.exists(file_path):\n",
    "            print(f\"Error: File not found for {location_code}\")\n",
    "            continue\n",
    "\n",
    "        # Load data with enforced daily frequency\n",
    "        df = load_cleaned_data(location_code, file_path)\n",
    "        if df is None:\n",
    "            continue\n",
    "\n",
    "        variables = ['SST', 'SWRad', 'WSPD']\n",
    "        seasonality = {'SST': 365, 'SWRad': 365, 'WSPD': 365}\n",
    "        thresholds = define_thresholds()\n",
    "        \n",
    "        forecasts = {}\n",
    "        test_forecasts = {}  # Store test period forecasts\n",
    "\n",
    "        for var in variables:\n",
    "            if var not in df.columns:\n",
    "                print(f\"Skipping {var} - not in dataset\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nForecasting {var} for {location_code}\")\n",
    "            \n",
    "            # Train model\n",
    "            model_fit, train_data, test_data = train_hw_model(\n",
    "                df, var, seasonal_periods=seasonality[var]\n",
    "            )\n",
    "\n",
    "            # Evaluate on test data\n",
    "            var_metrics, test_forecast = evaluate_model(model_fit, test_data, var)\n",
    "            \n",
    "            # Generate future forecast (365 days after training)\n",
    "            forecast_horizon = 365\n",
    "            last_train_date = train_data.index[-1]\n",
    "            future_dates = pd.date_range(\n",
    "                start=last_train_date + pd.Timedelta(days=1),\n",
    "                periods=forecast_horizon,\n",
    "                freq=train_data.index.freq  # Use same frequency\n",
    "            )\n",
    "            future_forecast = model_fit.forecast(forecast_horizon)\n",
    "            future_forecast = pd.Series(future_forecast, index=future_dates)\n",
    "\n",
    "            # Plot test period forecast and actuals\n",
    "            plot_forecasts(\n",
    "                train_data, \n",
    "                test_data, \n",
    "                test_forecast,  # Plot predictions for test period\n",
    "                var, \n",
    "                location_code, \n",
    "                output_dir\n",
    "            )\n",
    "\n",
    "            # Store forecasts\n",
    "            forecasts[var] = future_forecast\n",
    "            test_forecasts[var] = test_forecast  # For debugging\n",
    "\n",
    "        # Calculate monthly suitability using future forecasts\n",
    "        monthly_suitability = calculate_monthly_suitability(forecasts, thresholds)\n",
    "        \n",
    "        # Generate planting calendar\n",
    "        if not monthly_suitability.empty:\n",
    "            decision_df = make_planting_decisions(monthly_suitability)\n",
    "            generate_planting_calendar(decision_df, location_code, output_dir)\n",
    "            export_monthly_decisions(decision_df, location_code, output_dir)\n",
    "\n",
    "        print(f\"\\nCompleted processing for {location_code}\")\n",
    "\n",
    "    print(\"\\nAll locations processed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tugas-akhir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
