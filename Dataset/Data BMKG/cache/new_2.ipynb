{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output directory if it doesn't exist\n",
    "output_dir = 'rice_planting_dss_output'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plt(filename):\n",
    "    \"\"\"Save the current plot to the output directory.\"\"\"\n",
    "    plt.savefig(f'{output_dir}/{filename}.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Load and prepare BMKG data with proper date handling.\"\"\"\n",
    "    try:\n",
    "        # Read data with Date column present\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Raw data shape: {data.shape}\")\n",
    "        \n",
    "        # Check if necessary columns exist\n",
    "        required_columns = ['Date', 'TN', 'TX', 'TAVG', 'RH_AVG', 'RR']\n",
    "        missing_columns = [col for col in required_columns if col not in data.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            print(f\"Warning: Missing required columns: {missing_columns}\")\n",
    "            \n",
    "        # Check if Date column exists, if not try to create it from Year, Month, Day\n",
    "        if 'Date' not in data.columns and all(col in data.columns for col in ['Year', 'Month', 'Day']):\n",
    "            print(\"Creating Date column from Year, Month, Day columns\")\n",
    "            data['Date'] = pd.to_datetime(data[['Year', 'Month', 'Day']])\n",
    "        \n",
    "        # Convert Date to datetime and set as index\n",
    "        if 'Date' in data.columns:\n",
    "            data['Date'] = pd.to_datetime(data['Date'])\n",
    "            data.set_index('Date', inplace=True)\n",
    "            print(f\"Successfully loaded data with shape: {data.shape}\")\n",
    "            \n",
    "            # Display sample of loaded data\n",
    "            print(\"Sample of loaded data:\")\n",
    "            print(data.head(3))\n",
    "            return data\n",
    "        else:\n",
    "            print(\"Error: No Date column found or could be created\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    \"\"\"Clean and preprocess the data with improved methods.\"\"\"\n",
    "    # List columns that need to be fixed\n",
    "    cols_to_fix = ['TN', 'TX', 'TAVG', 'RH_AVG', 'RR', 'SS', 'FF_X', 'DDD_X', 'FF_AVG']\n",
    "    \n",
    "    # Clean: replace '-' with NaN, then convert to numeric\n",
    "    for col in cols_to_fix:\n",
    "        if col in data.columns:\n",
    "            data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    \n",
    "    # Handle 8888 and 9999 values (missing value codes)\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype != 'object':  # Only change numeric columns\n",
    "            data[col] = data[col].replace([8888, 9999], np.nan)\n",
    "\n",
    "    # Check missing values percentage\n",
    "    missing_percentage = data.isna().mean() * 100\n",
    "    print(\"Missing Values Percentage by Column:\")\n",
    "    for col, pct in missing_percentage.items():\n",
    "        print(f\"{col}: {pct:.2f}%\")\n",
    "    \n",
    "    # Create a copy for filled data\n",
    "    data_filled = data.copy()\n",
    "    \n",
    "    # Improved missing value handling\n",
    "    # For RR (rainfall), use time-based interpolation\n",
    "    if 'RR' in data_filled.columns:\n",
    "        # First interpolate using time-based method\n",
    "        data_filled['RR'] = data_filled['RR'].interpolate(method='time')\n",
    "        # Then fill any remaining NaNs\n",
    "        data_filled['RR'] = data_filled['RR'].fillna(method='ffill').fillna(method='bfill')\n",
    "        # Ensure no values are <= 0 for multiplicative models\n",
    "        data_filled['RR'] = data_filled['RR'].clip(lower=0.1)\n",
    "    \n",
    "    # For other columns, use standard ffill/bfill\n",
    "    for col in data_filled.columns:\n",
    "        if col != 'RR':  # Skip RR as we already handled it\n",
    "            data_filled[col] = data_filled[col].fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    return data, data_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze seasonal patterns\n",
    "def analyze_seasonality(data, variables):\n",
    "    \"\"\"Analyze seasonal patterns in time series data using ACF/PACF.\"\"\"\n",
    "    for var in variables:\n",
    "        if var in data.columns:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plot_acf(data[var].dropna(), lags=400, alpha=0.05)\n",
    "            plt.title(f'Autocorrelation Function for {var}')\n",
    "            save_plt(f'acf_{var}')\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plot_pacf(data[var].dropna(), lags=50, alpha=0.05)\n",
    "            plt.title(f'Partial Autocorrelation Function for {var}')\n",
    "            save_plt(f'pacf_{var}')\n",
    "            \n",
    "            print(f\"Saved ACF/PACF plots for {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Holt-Winters forecasting with improved parameters\n",
    "def forecast_variable(data, variable, period, forecast_days=120, seasonal_type='mul'):\n",
    "    \"\"\"\n",
    "    Apply Holt-Winters forecasting to a specific variable with improved parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        The input data with the variable to forecast\n",
    "    variable : str\n",
    "        The column name to forecast\n",
    "    period : int\n",
    "        Seasonal period (7=weekly, 30=monthly, 365=yearly)\n",
    "    forecast_days : int\n",
    "        Number of days to forecast\n",
    "    seasonal_type : str\n",
    "        Type of seasonal component ('mul' or 'add')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (model, forecast values, fitted values)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\nForecasting {variable} with seasonal period: {period} ({seasonal_type} seasonality)\")\n",
    "        \n",
    "        # Check if we have enough data points for the given period\n",
    "        if len(data) < 2 * period:\n",
    "            print(f\"Warning: Data length ({len(data)}) is less than twice the seasonal period ({period})\")\n",
    "        \n",
    "        # Create and fit the model\n",
    "        model = ExponentialSmoothing(\n",
    "            data[variable],\n",
    "            trend='add',  # Always use additive trend\n",
    "            seasonal=seasonal_type,  # Use parameter for flexibility\n",
    "            seasonal_periods=period\n",
    "        )\n",
    "        \n",
    "        # For RH_AVG, we can set some parameters directly if needed\n",
    "        if variable == 'RH_AVG':\n",
    "            fitted_model = model.fit(optimized=True, \n",
    "                                    smoothing_level=0.5,  # Make it more responsive to level changes\n",
    "                                    smoothing_seasonal=0.1)  # Increase seasonal component impact\n",
    "        else:\n",
    "            fitted_model = model.fit(optimized=True)\n",
    "        \n",
    "        # Generate forecast\n",
    "        forecast = fitted_model.forecast(forecast_days)\n",
    "        \n",
    "        # Get fitted values\n",
    "        fitted = fitted_model.fittedvalues\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(data[variable].iloc[period:], fitted.iloc[period:])\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(data[variable].iloc[period:], fitted.iloc[period:])\n",
    "        r2 = r2_score(data[variable].iloc[period:], fitted.iloc[period:])\n",
    "        \n",
    "        print(f\"Model parameters:\")\n",
    "        print(f\"  Alpha (level): {fitted_model.params['smoothing_level']:.4f}\")\n",
    "        print(f\"  Beta (trend): {fitted_model.params['smoothing_trend']:.4f}\")\n",
    "        print(f\"  Gamma (seasonal): {fitted_model.params['smoothing_seasonal']:.4f}\")\n",
    "        print(f\"Model performance:\")\n",
    "        print(f\"  MSE: {mse:.4f}\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAE: {mae:.4f}\")\n",
    "        print(f\"  R-squared: {r2:.4f}\")\n",
    "        \n",
    "        return fitted_model, forecast, fitted\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error forecasting {variable}: {str(e)}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification functions for the three main variables\n",
    "def classify_rr(value):\n",
    "    \"\"\"Classify rainfall values.\"\"\"\n",
    "    if pd.isna(value):  # Handle NaN values\n",
    "        return 'Tidak Ada Data (Risiko)'\n",
    "    elif value < 2:\n",
    "        return 'Kering (Risiko)'\n",
    "    elif 2 <= value <= 15:\n",
    "        return 'Optimal'\n",
    "    else:\n",
    "        return 'Banjir (Risiko)'\n",
    "\n",
    "def classify_tavg(value):\n",
    "    \"\"\"Classify average temperature values.\"\"\"\n",
    "    if pd.isna(value):  # Handle NaN values\n",
    "        return 'Tidak Ada Data (Risiko)'\n",
    "    elif value < 20:\n",
    "        return 'Dingin (Risiko)'\n",
    "    elif 20 <= value <= 35:\n",
    "        return 'Optimal'\n",
    "    else:\n",
    "        return 'Panas (Risiko)'\n",
    "\n",
    "def classify_rh(value):\n",
    "    \"\"\"Classify relative humidity values.\"\"\"\n",
    "    if pd.isna(value):  # Handle NaN values\n",
    "        return 'Tidak Ada Data (Risiko)'\n",
    "    elif value < 60:\n",
    "        return 'Kering (Risiko)'\n",
    "    elif 60 <= value <= 90:\n",
    "        return 'Optimal'\n",
    "    else:\n",
    "        return 'Lembab Ekstrem (Risiko)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate decision score and recommendation\n",
    "def calculate_decision(rr_value, tavg_value, rh_value, ss_value=None):\n",
    "    \"\"\"\n",
    "    Calculate decision score and recommendation based on weather parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rr_value : float\n",
    "        Rainfall value in mm\n",
    "    tavg_value : float\n",
    "        Average temperature in °C\n",
    "    rh_value : float\n",
    "        Relative humidity in %\n",
    "    ss_value : float, optional\n",
    "        Sunshine duration in hours\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (score, category, decision)\n",
    "    \"\"\"\n",
    "    # Check if we have valid data\n",
    "    if pd.isna(rr_value) and pd.isna(tavg_value) and pd.isna(rh_value):\n",
    "        return 0, 'Tidak Ada Data', 'Bera'\n",
    "    \n",
    "    # Get classifications\n",
    "    rr_status = classify_rr(rr_value)\n",
    "    tavg_status = classify_tavg(tavg_value)\n",
    "    rh_status = classify_rh(rh_value)\n",
    "    \n",
    "    # Initialize score\n",
    "    score = 0\n",
    "    \n",
    "    # Apply weighted scoring: RR (40%), TAVG (40%), RH_AVG (20%)\n",
    "    # Rainfall scoring\n",
    "    if not pd.isna(rr_value):  # Only score if we have data\n",
    "        if 'Optimal' in rr_status:\n",
    "            score += 40\n",
    "        elif 'Kering' in rr_status and rr_value >= 1:  # Some rain is better than none\n",
    "            score += 20\n",
    "    \n",
    "    # Temperature scoring\n",
    "    if not pd.isna(tavg_value):  # Only score if we have data\n",
    "        if 'Optimal' in tavg_status:\n",
    "            score += 40\n",
    "        elif tavg_value >= 18 and tavg_value < 20:  # Close to optimal\n",
    "            score += 30\n",
    "        elif tavg_value > 35 and tavg_value <= 37:  # Close to optimal\n",
    "            score += 30\n",
    "    \n",
    "    # Humidity scoring\n",
    "    if not pd.isna(rh_value):  # Only score if we have data\n",
    "        if 'Optimal' in rh_status:\n",
    "            score += 20\n",
    "        elif rh_value > 90 and rh_value <= 95:  # Slightly high but manageable\n",
    "            score += 10\n",
    "    \n",
    "    # Build category description\n",
    "    category_parts = []\n",
    "    if 'Optimal' not in rr_status:\n",
    "        category_parts.append(rr_status)\n",
    "    if 'Optimal' not in tavg_status:\n",
    "        category_parts.append(tavg_status)\n",
    "    if 'Optimal' not in rh_status:\n",
    "        category_parts.append(rh_status)\n",
    "    \n",
    "    if category_parts:\n",
    "        category = ', '.join(category_parts)\n",
    "    else:\n",
    "        category = 'Optimal'\n",
    "    \n",
    "    # Determine decision\n",
    "    if ('Banjir' in rr_status and not pd.isna(rr_value)) or \\\n",
    "       ('Panas' in tavg_status and not pd.isna(tavg_value)) or \\\n",
    "       (('Lembab Ekstrem' in rh_status) and not pd.isna(rh_value) and not pd.isna(rr_value) and rr_value > 10):\n",
    "        decision = 'Bera'  # Don't plant due to high risk\n",
    "    elif score >= 70:\n",
    "        decision = 'Tanam'  # Optimal conditions for planting\n",
    "    elif 50 <= score < 70:\n",
    "        decision = 'Tanam (Waspada)'  # Plant with caution\n",
    "    else:\n",
    "        decision = 'Bera'  # Don't plant due to suboptimal conditions\n",
    "    \n",
    "    return score, category, decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_harvest_conditions(forecast_df, planting_date):\n",
    "    \"\"\"\n",
    "    Check conditions for harvesting based on planting date.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    forecast_df : pandas.DataFrame\n",
    "        DataFrame with forecasted values\n",
    "    planting_date : str\n",
    "        Planting date in YYYY-MM-DD format\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with harvesting recommendations\n",
    "    \"\"\"\n",
    "    # Convert planting date to datetime\n",
    "    plant_date = pd.to_datetime(planting_date)\n",
    "    \n",
    "    # Define harvest window (90-100 days after planting)\n",
    "    harvest_start = plant_date + pd.Timedelta(days=90)\n",
    "    harvest_end = plant_date + pd.Timedelta(days=100)\n",
    "    \n",
    "    # Get forecast for harvest window plus a few days before and after\n",
    "    buffer_days = 7\n",
    "    window_start = harvest_start - pd.Timedelta(days=buffer_days)\n",
    "    window_end = harvest_end + pd.Timedelta(days=buffer_days)\n",
    "    \n",
    "    # Extract relevant forecast period\n",
    "    harvest_forecast = forecast_df[(forecast_df.index >= window_start) & \n",
    "                                  (forecast_df.index <= window_end)].copy()\n",
    "    \n",
    "    # Check for risky conditions during harvest\n",
    "    harvest_forecast['Rainfall_Risk'] = harvest_forecast['RR'] > 10\n",
    "    harvest_forecast['Humidity_Risk'] = harvest_forecast['RH_AVG'] > 90\n",
    "    \n",
    "    # Add recommendation column\n",
    "    def get_harvest_recommendation(row):\n",
    "        if row['Rainfall_Risk']:\n",
    "            if row.name >= harvest_start and row.name <= harvest_end:\n",
    "                return 'Percepat Panen (Risiko Hujan)'\n",
    "            else:\n",
    "                return 'Pantau Cuaca'\n",
    "        elif row['Humidity_Risk']:\n",
    "            if row.name >= harvest_start and row.name <= harvest_end:\n",
    "                return 'Pertimbangkan Panen (Kelembaban Tinggi)'\n",
    "            else:\n",
    "                return 'Pantau Kelembaban'\n",
    "        elif row.name >= harvest_start and row.name <= harvest_end:\n",
    "            return 'Panen Sesuai Jadwal'\n",
    "        else:\n",
    "            return 'Belum Waktunya Panen'\n",
    "    \n",
    "    harvest_forecast['Rekomendasi'] = harvest_forecast.apply(get_harvest_recommendation, axis=1)\n",
    "    \n",
    "    return harvest_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_forecasts(original_data, forecast_df, variable, period):\n",
    "    \"\"\"Create visualization for forecasting results.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot historical data (last 365 days)\n",
    "    historical_data = original_data[variable].iloc[-365:]\n",
    "    plt.plot(historical_data.index, historical_data, \n",
    "             label='Data Historis', color='gray', alpha=0.7)\n",
    "    \n",
    "    # Plot forecast\n",
    "    plt.plot(forecast_df.index, forecast_df[variable], \n",
    "             label=f'Forecast (period={period})', \n",
    "             color='blue', linewidth=2)\n",
    "    \n",
    "    # Add confidence intervals\n",
    "    plt.fill_between(forecast_df.index, \n",
    "                     forecast_df[f'{variable}_Lower'], \n",
    "                     forecast_df[f'{variable}_Upper'], \n",
    "                     color='blue', alpha=0.2)\n",
    "    \n",
    "    plt.title(f'Forecast {variable} dengan Seasonal Period {period} Hari')\n",
    "    plt.xlabel('Tanggal')\n",
    "    plt.ylabel(variable)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    save_plt(f'forecast_{variable}_period_{period}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_decisions(decision_df):\n",
    "    \"\"\"Create visualization for the decision support results.\"\"\"\n",
    "    # Plot decisions timeline\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Convert decision to numeric for plotting\n",
    "    decision_map = {'Bera': 0, 'Tanam (Waspada)': 1, 'Tanam': 2}\n",
    "    decision_df['Decision_Value'] = decision_df['Keputusan'].map(\n",
    "        lambda x: decision_map.get(x, 0) if 'Panen' not in x else 3\n",
    "    )\n",
    "    \n",
    "    # Plot score\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(decision_df.index, decision_df['Skor'], \n",
    "             marker='o', linestyle='-', markersize=4)\n",
    "    plt.fill_between(decision_df.index, 0, decision_df['Skor'], alpha=0.3)\n",
    "    plt.axhline(y=70, color='green', linestyle='--', alpha=0.7, label='Batas Optimal (70%)')\n",
    "    plt.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='Batas Waspada (50%)')\n",
    "    plt.title('Skor Keputusan untuk Penanaman Padi')\n",
    "    plt.ylabel('Skor (%)')\n",
    "    plt.ylim(0, 105)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot decisions\n",
    "    plt.subplot(2, 1, 2)\n",
    "    colors = ['red', 'orange', 'green', 'blue']\n",
    "    decision_colors = [colors[val] for val in decision_df['Decision_Value']]\n",
    "    \n",
    "    plt.scatter(decision_df.index, decision_df['Decision_Value'], \n",
    "                c=decision_colors, s=50)\n",
    "    plt.yticks([0, 1, 2, 3], ['Bera', 'Tanam (Waspada)', 'Tanam', 'Panen'])\n",
    "    plt.title('Rekomendasi Penanaman Padi')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_plt('rice_planting_decisions_timeline')\n",
    "    \n",
    "    # Create a second visualization for parameter distributions\n",
    "    try:\n",
    "        # Get unique decisions and skip plotting if we don't have at least one value for each\n",
    "        unique_decisions = decision_df['Keputusan'].unique()\n",
    "        \n",
    "        if len(unique_decisions) > 0:\n",
    "            plt.figure(figsize=(16, 12))\n",
    "            \n",
    "            # Use manual plotting instead of seaborn for more control\n",
    "            plt.subplot(2, 2, 1)\n",
    "            for i, decision in enumerate(unique_decisions):\n",
    "                subset = decision_df[decision_df['Keputusan'] == decision]['RR'].dropna()\n",
    "                if len(subset) > 0:  # Only plot if we have data\n",
    "                    plt.boxplot(subset, positions=[i+1], widths=0.6)\n",
    "            plt.xticks(range(1, len(unique_decisions)+1), unique_decisions)\n",
    "            plt.title('Curah Hujan Berdasarkan Keputusan')\n",
    "            plt.axhline(y=2, color='orange', linestyle='--', label='Batas Kering (2mm)')\n",
    "            plt.axhline(y=15, color='red', linestyle='--', label='Batas Banjir (15mm)')\n",
    "            plt.legend()\n",
    "            \n",
    "            # Temperature by decision\n",
    "            plt.subplot(2, 2, 2)\n",
    "            for i, decision in enumerate(unique_decisions):\n",
    "                subset = decision_df[decision_df['Keputusan'] == decision]['TAVG'].dropna()\n",
    "                if len(subset) > 0:  # Only plot if we have data\n",
    "                    plt.boxplot(subset, positions=[i+1], widths=0.6)\n",
    "            plt.xticks(range(1, len(unique_decisions)+1), unique_decisions)\n",
    "            plt.title('Suhu Rata-rata Berdasarkan Keputusan')\n",
    "            plt.axhline(y=20, color='blue', linestyle='--', label='Batas Dingin (20°C)')\n",
    "            plt.axhline(y=35, color='red', linestyle='--', label='Batas Panas (35°C)')\n",
    "            plt.legend()\n",
    "            \n",
    "            # Humidity by decision\n",
    "            plt.subplot(2, 2, 3)\n",
    "            for i, decision in enumerate(unique_decisions):\n",
    "                subset = decision_df[decision_df['Keputusan'] == decision]['RH_AVG'].dropna()\n",
    "                if len(subset) > 0:  # Only plot if we have data\n",
    "                    plt.boxplot(subset, positions=[i+1], widths=0.6)\n",
    "            plt.xticks(range(1, len(unique_decisions)+1), unique_decisions)\n",
    "            plt.title('Kelembaban Relatif Berdasarkan Keputusan')\n",
    "            plt.axhline(y=60, color='orange', linestyle='--', label='Batas Kering (60%)')\n",
    "            plt.axhline(y=90, color='blue', linestyle='--', label='Batas Lembab (90%)')\n",
    "            plt.legend()\n",
    "            \n",
    "            # Score by decision\n",
    "            plt.subplot(2, 2, 4)\n",
    "            for i, decision in enumerate(unique_decisions):\n",
    "                subset = decision_df[decision_df['Keputusan'] == decision]['Skor'].dropna()\n",
    "                if len(subset) > 0:  # Only plot if we have data\n",
    "                    plt.boxplot(subset, positions=[i+1], widths=0.6)\n",
    "            plt.xticks(range(1, len(unique_decisions)+1), unique_decisions)\n",
    "            plt.title('Distribusi Skor Berdasarkan Keputusan')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            save_plt('decision_parameters_distribution')\n",
    "        else:\n",
    "            print(\"Warning: No unique decisions found for boxplot visualization\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in boxplot visualization: {str(e)}\")\n",
    "        # Create a simple figure with error message\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.text(0.5, 0.5, f'Visualisasi boxplot gagal: {str(e)}',\n",
    "                ha='center', va='center', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        save_plt('decision_parameters_distribution_error')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the Rice Planting Decision Support System.\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SISTEM PENDUKUNG KEPUTUSAN PENANAMAN PADI BERBASIS FORECASTING HOLT-WINTERS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. Load and preprocess data\n",
    "    print(\"\\nSTEP 1: Loading and preprocessing data...\")\n",
    "    data_path = input(\"Enter the path to the BMKG data CSV file: \")\n",
    "    data = load_data(data_path)\n",
    "    \n",
    "    if data is None:\n",
    "        print(\"Failed to load data. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    raw_data, filled_data = preprocess_data(data)\n",
    "    \n",
    "    # 1a. Analyze seasonal patterns before forecasting\n",
    "    print(\"\\nSTEP 1a: Analyzing seasonal patterns...\")\n",
    "    analyze_seasonality(filled_data, ['RR', 'TAVG', 'RH_AVG'])\n",
    "    \n",
    "    # 2. Perform Holt-Winters forecasting for each selected variable\n",
    "    print(\"\\nSTEP 2: Forecasting weather variables...\")\n",
    "    \n",
    "    # Variables and their seasonal periods (updated based on analysis)\n",
    "    forecast_variables = {\n",
    "        'RR': (365, 'add'),   # Rainfall (yearly seasonality, additive to handle zeros)\n",
    "        'TAVG': (7, 'add'),   # Average temperature (weekly seasonality, changed from 30)\n",
    "        'RH_AVG': (3, 'add')  # Relative humidity (changed from 7 to 3 days)\n",
    "    }\n",
    "    \n",
    "    # Prepare forecasting\n",
    "    forecast_days = 120  # 4 months forecast\n",
    "    forecast_start_date = filled_data.index[-1] + pd.Timedelta(days=1)\n",
    "    forecast_dates = pd.date_range(start=forecast_start_date, periods=forecast_days, freq='D')\n",
    "    \n",
    "    # Initialize forecast dataframe\n",
    "    forecast_results = pd.DataFrame(index=forecast_dates)\n",
    "    \n",
    "    # Run forecasts for each variable\n",
    "    models = {}\n",
    "    for var, (period, seasonal_type) in forecast_variables.items():\n",
    "        if var in filled_data.columns:\n",
    "            model, forecast, fitted = forecast_variable(filled_data, var, period, forecast_days, seasonal_type)\n",
    "            \n",
    "            if model is not None:\n",
    "                # Store in the forecast results\n",
    "                forecast_results[var] = forecast\n",
    "                \n",
    "                # Calculate confidence intervals (95%)\n",
    "                mse = mean_squared_error(filled_data[var].iloc[period:], fitted.iloc[period:])\n",
    "                rmse = np.sqrt(mse)\n",
    "                \n",
    "                forecast_results[f'{var}_Lower'] = forecast - 1.96 * rmse\n",
    "                forecast_results[f'{var}_Upper'] = forecast + 1.96 * rmse\n",
    "                \n",
    "                # Ensure no negative values in forecast\n",
    "                if var == 'RR':\n",
    "                    forecast_results[var] = forecast_results[var].clip(lower=0)\n",
    "                    forecast_results[f'{var}_Lower'] = forecast_results[f'{var}_Lower'].clip(lower=0)\n",
    "                \n",
    "                # Store model for later use\n",
    "                models[var] = model\n",
    "                \n",
    "                # Visualize forecast\n",
    "                visualize_forecasts(filled_data, forecast_results, var, period)\n",
    "        else:\n",
    "            print(f\"Warning: Variable {var} not found in the dataset.\")\n",
    "    \n",
    "    # 3. Check if sunshine duration (SS) is available\n",
    "    if 'SS' in filled_data.columns:\n",
    "        # Use a simpler method for SS forecasting (e.g., monthly seasonality)\n",
    "        model_ss, forecast_ss, fitted_ss = forecast_variable(filled_data, 'SS', 30, forecast_days, 'add')\n",
    "        if model_ss is not None:\n",
    "            forecast_results['SS'] = forecast_ss\n",
    "            \n",
    "            # Calculate confidence intervals\n",
    "            mse_ss = mean_squared_error(filled_data['SS'].iloc[30:], fitted_ss.iloc[30:])\n",
    "            rmse_ss = np.sqrt(mse_ss)\n",
    "            \n",
    "            forecast_results['SS_Lower'] = forecast_ss - 1.96 * rmse_ss\n",
    "            forecast_results['SS_Upper'] = forecast_ss + 1.96 * rmse_ss\n",
    "            \n",
    "            # Visualize forecast\n",
    "            visualize_forecasts(filled_data, forecast_results, 'SS', 30)\n",
    "    \n",
    "    # Print a preview of forecast results\n",
    "    print(\"\\nPreview of forecast results:\")\n",
    "    print(forecast_results.head())  # Debug line to check forecast values\n",
    "    \n",
    "    # 4. Apply decision support logic\n",
    "    print(\"\\nSTEP 3: Applying decision support logic...\")\n",
    "    \n",
    "    # Create a copy of the forecast results for decision making\n",
    "    decision_df = forecast_results.copy()\n",
    "    \n",
    "    # Set negative values to 0 (can't have negative rainfall, etc.)\n",
    "    for var in forecast_variables.keys():\n",
    "        if var in decision_df.columns:\n",
    "            decision_df[var] = decision_df[var].clip(lower=0)\n",
    "    \n",
    "    # Apply the decision logic for each day in the forecast\n",
    "    decision_df['Skor'] = 0\n",
    "    decision_df['Kategori'] = ''\n",
    "    decision_df['Keputusan'] = ''\n",
    "    \n",
    "    # Debug: count valid forecast days\n",
    "    valid_days = 0\n",
    "    \n",
    "    for idx, row in decision_df.iterrows():\n",
    "        try:\n",
    "            # Check if we have the required variables (even if NaN)\n",
    "            required_vars = list(forecast_variables.keys())\n",
    "            missing_vars = [var for var in required_vars if var not in row.index]\n",
    "            \n",
    "            if missing_vars:\n",
    "                print(f\"Warning: Missing variables {missing_vars} for date {idx}\")\n",
    "                continue\n",
    "                \n",
    "            # Get values, may be NaN\n",
    "            rr_val = row['RR'] if 'RR' in row else np.nan\n",
    "            tavg_val = row['TAVG'] if 'TAVG' in row else np.nan\n",
    "            rh_val = row['RH_AVG'] if 'RH_AVG' in row else np.nan\n",
    "            ss_val = row.get('SS', np.nan)\n",
    "            \n",
    "            # Debug print to check values\n",
    "            if idx.day == 1 or valid_days < 5:  # Print first few days or 1st of each month\n",
    "                print(f\"Day {idx}: RR={rr_val:.2f}, TAVG={tavg_val:.2f}, RH={rh_val:.2f}\")\n",
    "                valid_days += 1\n",
    "            \n",
    "            # Calculate decision using updated function that handles NaN\n",
    "            score, category, decision = calculate_decision(rr_val, tavg_val, rh_val, ss_val)\n",
    "            \n",
    "            # Store results\n",
    "            decision_df.at[idx, 'Skor'] = score\n",
    "            decision_df.at[idx, 'Kategori'] = category\n",
    "            decision_df.at[idx, 'Keputusan'] = decision\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating decision for {idx}: {str(e)}\")\n",
    "    \n",
    "    # 5. Check harvesting conditions\n",
    "    print(\"\\nSTEP 4: Checking harvesting conditions...\")\n",
    "    planting_date = input(\"Enter a reference planting date (YYYY-MM-DD) or press Enter to skip: \")\n",
    "    \n",
    "    if planting_date:\n",
    "        try:\n",
    "            harvest_forecast = check_harvest_conditions(decision_df, planting_date)\n",
    "            \n",
    "            # Apply harvesting decisions to main decision dataframe\n",
    "            for idx, row in harvest_forecast.iterrows():\n",
    "                if 'Panen' in row['Rekomendasi']:\n",
    "                    decision_df.at[idx, 'Keputusan'] = row['Rekomendasi']\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking harvest conditions: {str(e)}\")\n",
    "    \n",
    "    # 6. Visualize and save results\n",
    "    print(\"\\nSTEP 5: Visualizing and saving results...\")\n",
    "    visualize_decisions(decision_df)\n",
    "    \n",
    "    # 7. Save results to CSV with proper column naming\n",
    "    output_file = f'{output_dir}/rice_planting_decisions.csv'\n",
    "    decision_columns = ['RR', 'TAVG', 'RH_AVG', 'Skor', 'Kategori', 'Keputusan']\n",
    "    if 'SS' in decision_df.columns:\n",
    "        decision_columns.insert(3, 'SS')\n",
    "    \n",
    "    # Create output dataframe with Tanggal column first\n",
    "    decision_output = decision_df[decision_columns].copy()\n",
    "    decision_output.reset_index(inplace=True)\n",
    "    decision_output.rename(columns={'index': 'Tanggal'}, inplace=True)\n",
    "    \n",
    "    # Reorganize columns to ensure Tanggal is first\n",
    "    final_columns = ['Tanggal'] + decision_columns\n",
    "    decision_output = decision_output[final_columns]\n",
    "    \n",
    "    # Save to CSV without index\n",
    "    decision_output.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nDecision support results saved to {output_file}\")\n",
    "    \n",
    "    # Display sample of results with proper column ordering\n",
    "    print(\"\\nSample of Decision Support Results:\")\n",
    "    print(decision_output.head(10))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"RICE PLANTING DECISION SUPPORT SYSTEM COMPLETED\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tugas-akhir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
