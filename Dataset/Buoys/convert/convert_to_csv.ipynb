{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ascii_to_csv(input_file, output_file=None):\n",
    "    \"\"\"\n",
    "    Mengkonversi file ASCII dari data buoy RAMA menjadi format CSV.\n",
    "    Secara otomatis mendeteksi format file berdasarkan struktur data.\n",
    "    \n",
    "    Parameters:\n",
    "    input_file (str): Path ke file ASCII\n",
    "    output_file (str, optional): Path untuk menyimpan file CSV hasil.\n",
    "    \n",
    "    Returns:\n",
    "    str: Path ke file CSV yang dihasilkan\n",
    "    \"\"\"\n",
    "    if output_file is None:\n",
    "        output_file = os.path.splitext(input_file)[0] + '.csv'\n",
    "    \n",
    "    # Baca beberapa baris pertama untuk identifikasi format\n",
    "    with open(input_file, 'r') as f:\n",
    "        preview_lines = [f.readline() for _ in range(20)]\n",
    "    \n",
    "    # Deteksi tipe format file:\n",
    "    # 1. Format Temperatur (multi-depth dengan pola Index:, multiple columns)\n",
    "    # 2. Format Angin (multiple variables pada kedalaman yang sama)\n",
    "    # 3. Format Umum (single variable dengan simple structure)\n",
    "    \n",
    "    is_temperature_format = False\n",
    "    is_wind_format = False\n",
    "    \n",
    "    # Cek apakah ada baris Index:\n",
    "    has_index_line = any('Index:' in line for line in preview_lines)\n",
    "    \n",
    "    # Cek pola depth pada file temperatur\n",
    "    depth_pattern = False\n",
    "    for line in preview_lines:\n",
    "        if 'Depth(M):' in line and len(line.split()) > 6:\n",
    "            # Jika ada banyak nilai kedalaman pada baris ini\n",
    "            try:\n",
    "                # Coba convert beberapa nilai ke float untuk konfirmasi multi-depth\n",
    "                depth_parts = line.split(':')[1].strip().split()\n",
    "                depth_count = sum(1 for part in depth_parts if re.match(r'^\\d+\\.?\\d*$', part))\n",
    "                if depth_count >= 3:  # Jika ada minimal 3 nilai depth\n",
    "                    depth_pattern = True\n",
    "                    break\n",
    "            except (ValueError, IndexError):\n",
    "                pass\n",
    "    \n",
    "    # Cek pola file angin (multiple variables dengan single depth)\n",
    "    wind_pattern = False\n",
    "    for i, line in enumerate(preview_lines):\n",
    "        if 'Depth (M):' in line and 'WDIR' in ''.join(preview_lines[i:i+3]):\n",
    "            wind_pattern = True\n",
    "            break\n",
    "    \n",
    "    # Tentukan format berdasarkan pola yang terdeteksi\n",
    "    if has_index_line and depth_pattern:\n",
    "        is_temperature_format = True\n",
    "    elif wind_pattern:\n",
    "        is_wind_format = True\n",
    "    \n",
    "    # Debug output\n",
    "    if is_temperature_format:\n",
    "        print(f\"📊 Terdeteksi format suhu (multi-kedalaman) dari {input_file}\")\n",
    "        return convert_temperature_ascii_to_csv(input_file, output_file)\n",
    "    elif is_wind_format:\n",
    "        print(f\"🌬️ Terdeteksi format angin dari {input_file}\")\n",
    "        return convert_wind_ascii_to_csv(input_file, output_file)\n",
    "    else:\n",
    "        print(f\"📋 Terdeteksi format umum dari {input_file}\")\n",
    "        return convert_general_ascii_to_csv(input_file, output_file)\n",
    "\n",
    "def convert_temperature_ascii_to_csv(input_file, output_file):\n",
    "    \"\"\"Fungsi untuk konversi file format suhu multi-kedalaman\"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Cari informasi kedalaman\n",
    "    depth_line = None\n",
    "    for line in lines:\n",
    "        if 'Depth(M):' in line:\n",
    "            depth_line = line.strip()\n",
    "            break\n",
    "    \n",
    "    if not depth_line:\n",
    "        print(\"❌ Tidak dapat menemukan informasi kedalaman\")\n",
    "        return None\n",
    "    \n",
    "    # Ekstrak nilai kedalaman untuk digunakan sebagai nama kolom\n",
    "    depth_parts = depth_line.split(':')[1].strip().split()\n",
    "    depth_values = []\n",
    "    for part in depth_parts:\n",
    "        try:\n",
    "            depth = float(part)\n",
    "            depth_values.append(f\"TEMP_{depth}m\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Jika kedalaman pertama adalah 1, itu SST (Sea Surface Temperature)\n",
    "    if depth_values and \"TEMP_1.0m\" in depth_values[0]:\n",
    "        depth_values[0] = \"SST\"\n",
    "    \n",
    "    # Buat struktur untuk data\n",
    "    data_rows = []\n",
    "    \n",
    "    # Proses baris data\n",
    "    for line in lines:\n",
    "        if re.match(r'^\\s*\\d{8}\\s+\\d{4}', line):\n",
    "            parts = line.strip().split()\n",
    "            \n",
    "            # Ambil tanggal dan waktu\n",
    "            date = parts[0]\n",
    "            time = parts[1]\n",
    "            \n",
    "            quality_start_idx = -1\n",
    "            for i, val in enumerate(parts[2:], 2):\n",
    "                if re.match(r'^[1-5]+$', val) and len(val) > 8:\n",
    "                    quality_start_idx = i\n",
    "                    break\n",
    "            \n",
    "            # Jika tidak menemukan kolom QUALITY/SOURCE, gunakan semua nilai\n",
    "            if quality_start_idx == -1:\n",
    "                temp_values = parts[2:]\n",
    "            else:\n",
    "                temp_values = parts[2:quality_start_idx]\n",
    "            \n",
    "            # Pastikan jumlah nilai sesuai dengan jumlah kedalaman\n",
    "            if len(temp_values) > len(depth_values):\n",
    "                temp_values = temp_values[:len(depth_values)]\n",
    "            elif len(temp_values) < len(depth_values):\n",
    "                # Isi dengan NaN jika kurang\n",
    "                temp_values.extend(['NaN'] * (len(depth_values) - len(temp_values)))\n",
    "            \n",
    "            # Gabungkan tanggal, waktu, dan nilai suhu\n",
    "            row_data = {'YYYYMMDD': date, 'HHMM': time}\n",
    "            for i, depth_name in enumerate(depth_values):\n",
    "                if i < len(temp_values):\n",
    "                    row_data[depth_name] = temp_values[i]\n",
    "                else:\n",
    "                    row_data[depth_name] = 'NaN'\n",
    "            \n",
    "            data_rows.append(row_data)\n",
    "    \n",
    "    # Buat DataFrame\n",
    "    df = pd.DataFrame(data_rows)\n",
    "    \n",
    "    # Debug: tampilkan kolom yang berhasil diproses\n",
    "    print(f\"Kolom yang berhasil diproses: {df.columns.tolist()}\")\n",
    "    print(f\"Jumlah baris data: {len(df)}\")\n",
    "    \n",
    "    # Gabungkan kolom tanggal dan waktu ke timestamp\n",
    "    df['Timestamp'] = pd.to_datetime(df['YYYYMMDD'] + ' ' + df['HHMM'], format='%Y%m%d %H%M', errors='coerce')\n",
    "    \n",
    "    # Hapus kolom asli tanggal dan waktu\n",
    "    df.drop(['YYYYMMDD', 'HHMM'], axis=1, inplace=True)\n",
    "    \n",
    "    # Konversi nilai suhu ke numerik\n",
    "    for col in df.columns:\n",
    "        if col != 'Timestamp':\n",
    "            df[col] = df[col].replace('-9.999', 'NaN')\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Simpan ke CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Berhasil menyimpan {len(df)} baris data ke {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "def convert_wind_ascii_to_csv(input_file, output_file):\n",
    "    \"\"\"Fungsi khusus untuk konversi file format angin\"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Cari header data\n",
    "    header_line = None\n",
    "    depth_line = None\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if 'Depth (M):' in line:\n",
    "            depth_line = line\n",
    "            # Header biasanya berada pada baris setelah Depth\n",
    "            if i + 1 < len(lines):\n",
    "                header_line = lines[i + 1]\n",
    "            break\n",
    "    \n",
    "    if not header_line or not depth_line:\n",
    "        print(\"❌ Tidak dapat menemukan header atau kedalaman untuk file angin\")\n",
    "        return None\n",
    "    \n",
    "    # Ekstrak header\n",
    "    headers = header_line.strip().split()\n",
    "    \n",
    "    # Identifikasi header yang valid (YYYYMMDD, HHMM, UWND, VWND, WSPD, WDIR)\n",
    "    valid_headers = []\n",
    "    for header in headers:\n",
    "        if header in ['YYYYMMDD', 'HHMM', 'UWND', 'VWND', 'WSPD', 'WDIR']:\n",
    "            valid_headers.append(header)\n",
    "    \n",
    "    # Baca data\n",
    "    data_rows = []\n",
    "    for line in lines:\n",
    "        if re.match(r'^\\s*\\d{8}\\s+\\d{4}', line):\n",
    "            parts = line.strip().split()\n",
    "            \n",
    "            # Ambil tanggal, waktu, dan komponen angin\n",
    "            row_data = {}\n",
    "            for i, header in enumerate(headers):\n",
    "                if i < len(parts) and header in valid_headers:\n",
    "                    row_data[header] = parts[i]\n",
    "            \n",
    "            if len(row_data) >= 2:  # Minimal ada tanggal dan waktu\n",
    "                data_rows.append(row_data)\n",
    "    \n",
    "    # Buat DataFrame\n",
    "    df = pd.DataFrame(data_rows)\n",
    "    \n",
    "    # Debug: tampilkan kolom yang berhasil diproses\n",
    "    print(f\"Kolom yang berhasil diproses: {df.columns.tolist()}\")\n",
    "    print(f\"Jumlah baris data: {len(df)}\")\n",
    "    \n",
    "    # Gabungkan kolom tanggal dan waktu ke timestamp\n",
    "    if 'YYYYMMDD' in df.columns and 'HHMM' in df.columns:\n",
    "        df['Timestamp'] = pd.to_datetime(df['YYYYMMDD'] + ' ' + df['HHMM'], format='%Y%m%d %H%M', errors='coerce')\n",
    "        df.drop(['YYYYMMDD', 'HHMM'], axis=1, inplace=True)\n",
    "    \n",
    "    # Konversi nilai angin ke numerik dan tangani missing values\n",
    "    for col in df.columns:\n",
    "        if col != 'Timestamp':\n",
    "            df[col] = df[col].apply(lambda x: np.nan if re.match(r'^-\\d{1,2}\\.?\\d*$', str(x)) else x)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Simpan ke CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Berhasil menyimpan {len(df)} baris data ke {output_file}\")\n",
    "    \n",
    "    # Tampilkan total missing values\n",
    "    missing_values_df = df.isnull().sum().to_frame(name=\"Jumlah Missing Values\")\n",
    "    missing_values_df.loc[\"Total Data yang hilang\"] = missing_values_df.sum()\n",
    "    print(\"Total Baris Hilang per Kolom:\\n\")\n",
    "    print(missing_values_df)\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "def convert_general_ascii_to_csv(input_file, output_file):\n",
    "    \"\"\"Fungsi untuk konversi file format umum (rad, rain, rh, sst)\"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Identifikasi header kolom dan data\n",
    "    data_rows = []\n",
    "    header_line = None\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if 'YYYYMMDD' in line and 'HHMM' in line:\n",
    "            header_line = line\n",
    "            break\n",
    "    \n",
    "    if not header_line:\n",
    "        print(\"❌ Tidak dapat menemukan header untuk file\")\n",
    "        return None\n",
    "    \n",
    "    # Ekstrak header\n",
    "    headers = header_line.strip().split()\n",
    "    \n",
    "    # Identifikasi kolom-kolom data (bukan QUALITY/SOURCE)\n",
    "    valid_headers = []\n",
    "    for header in headers:\n",
    "        if header not in ['QUALITY', 'SOURCE'] and header != '':\n",
    "            valid_headers.append(header)\n",
    "    \n",
    "    # Proses baris data\n",
    "    for line in lines:\n",
    "        if re.match(r'^\\s*\\d{8}\\s+\\d{4}', line):\n",
    "            parts = line.strip().split()\n",
    "            \n",
    "            # Pastikan panjang data sesuai dengan header\n",
    "            if len(parts) >= len(valid_headers):\n",
    "                # Ambil data sesuai header yang valid\n",
    "                row_data = {header: parts[i] for i, header in enumerate(headers) if i < len(parts) and header in valid_headers}\n",
    "                \n",
    "                if len(row_data) >= 2:  # Minimal ada tanggal dan waktu\n",
    "                    data_rows.append(row_data)\n",
    "    \n",
    "    # Buat DataFrame\n",
    "    df = pd.DataFrame(data_rows)\n",
    "    \n",
    "    # Debug: tampilkan kolom yang berhasil diproses\n",
    "    print(f\"Kolom yang berhasil diproses: {df.columns.tolist()}\")\n",
    "    print(f\"Jumlah baris data: {len(df)}\")\n",
    "    \n",
    "    # Gabungkan kolom tanggal dan waktu ke timestamp\n",
    "    if 'YYYYMMDD' in df.columns and 'HHMM' in df.columns:\n",
    "        df['Timestamp'] = pd.to_datetime(df['YYYYMMDD'] + ' ' + df['HHMM'], format='%Y%m%d %H%M', errors='coerce')\n",
    "        df.drop(['YYYYMMDD', 'HHMM'], axis=1, inplace=True)\n",
    "    \n",
    "    # Konversi nilai ke numerik dan tangani missing values\n",
    "    for col in df.columns:\n",
    "        if col != 'Timestamp':\n",
    "            # Identifikasi dan ganti nilai missing sesuai dengan pattern yang umum\n",
    "            df[col] = df[col].apply(lambda x: np.nan if re.match(r'^-9\\.9+$|^-999\\.9+$', str(x)) else x)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Simpan ke CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Berhasil menyimpan {len(df)} baris data ke {output_file}\")\n",
    "    \n",
    "    # Tampilkan total missing values\n",
    "    missing_values_df = df.isnull().sum().to_frame(name=\"Jumlah Missing Values\")\n",
    "    missing_values_df.loc[\"Total Data yang hilang\"] = missing_values_df.sum()\n",
    "    print(\"Total Baris Hilang per Kolom:\\n\")\n",
    "    print(missing_values_df)\n",
    "    \n",
    "    return output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_files(input_directory, output_directory=None, file_pattern='*.ascii'):\n",
    "    \"\"\"\n",
    "    Memproses banyak file ASCII dalam satu direktori.\n",
    "    \n",
    "    Parameters:\n",
    "    input_directory (str): Path ke direktori yang berisi file ASCII\n",
    "    output_directory (str, optional): Path direktori untuk menyimpan file CSV hasil\n",
    "    file_pattern (str, optional): Pola file yang akan diproses (default: *.ascii)\n",
    "    \n",
    "    Returns:\n",
    "    list: Daftar path file CSV yang dihasilkan\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(input_directory):\n",
    "        print(f\"❌ Direktori tidak ditemukan: {input_directory}\")\n",
    "        return []\n",
    "    \n",
    "    # Buat output directory jika belum ada\n",
    "    if output_directory is None:\n",
    "        output_directory = os.path.join(input_directory, 'convert')\n",
    "    elif not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "        print(f\"📁 Membuat direktori output: {output_directory}\")\n",
    "    \n",
    "    \n",
    "    # Pastikan folder output ada\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    processed_files = []\n",
    "    \n",
    "    # Cari semua file yang sesuai pola\n",
    "    for input_file in glob.glob(os.path.join(input_directory, file_pattern)):\n",
    "        filename = os.path.basename(input_file)\n",
    "        output_file = os.path.join(output_directory, os.path.splitext(filename)[0] + '.csv')\n",
    "        \n",
    "        print(f\"\\n🔄 Memproses {filename}...\")\n",
    "        try:\n",
    "            result = convert_ascii_to_csv(input_file, output_file)\n",
    "            if result:\n",
    "                processed_files.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error saat memproses {filename}: {str(e)}\")\n",
    "            \n",
    "    \n",
    "    print(f\"\\n✅ Selesai memproses {len(processed_files)} dari {len(glob.glob(os.path.join(input_directory, file_pattern)))} file\")\n",
    "    return processed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_excel(df, output_file):\n",
    "    \"\"\"\n",
    "    Menyimpan DataFrame ke format Excel dengan penyesuaian lebar kolom otomatis.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame yang akan disimpan\n",
    "    output_file (str): Path untuk menyimpan file Excel\n",
    "    \n",
    "    Returns:\n",
    "    str: Path ke file Excel yang dihasilkan\n",
    "    \"\"\"\n",
    "    # Ganti ekstensi file dari .csv ke .xlsx\n",
    "    excel_file = output_file.replace('.csv', '.xlsx')\n",
    "    \n",
    "    # Buat Excel writer dengan xlsxwriter engine\n",
    "    writer = pd.ExcelWriter(excel_file, engine='xlsxwriter')\n",
    "    \n",
    "    try:\n",
    "        # Tulis DataFrame ke Excel\n",
    "        df.to_excel(writer, index=False, sheet_name='Data')\n",
    "        \n",
    "        # Dapatkan workbook dan worksheet\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Data']\n",
    "        \n",
    "        # Format untuk tanggal\n",
    "        date_format = workbook.add_format({'num_format': 'yyyy-mm-dd'})\n",
    "        \n",
    "        # Sesuaikan lebar kolom\n",
    "        for idx, col in enumerate(df.columns):\n",
    "            # Hitung lebar maksimum\n",
    "            max_length = max(\n",
    "                df[col].astype(str).apply(len).max(),  # Panjang data\n",
    "                len(str(col))  # Panjang header\n",
    "            )\n",
    "            \n",
    "            # Tambahkan sedikit padding\n",
    "            adjusted_width = max_length + 2\n",
    "            \n",
    "            # Set lebar kolom\n",
    "            worksheet.set_column(idx, idx, adjusted_width)\n",
    "            \n",
    "            # Terapkan format date untuk kolom Date\n",
    "            if col == 'Date':\n",
    "                worksheet.set_column(idx, idx, adjusted_width, date_format)\n",
    "        \n",
    "        # Simpan file\n",
    "        writer.close()\n",
    "        print(f\"✅ Berhasil menyimpan ke Excel: {excel_file}\")\n",
    "        return excel_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saat menyimpan Excel: {str(e)}\")\n",
    "        writer.close()\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date_columns(df):\n",
    "    \"\"\"\n",
    "    Memproses kolom timestamp menjadi komponen tanggal terpisah\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame untuk diproses\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame dengan kolom tanggal yang diperbarui\n",
    "    \"\"\"\n",
    "    if 'Timestamp' in df.columns:\n",
    "        # Konversi timestamp ke datetime jika belum\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        \n",
    "        # Buat kolom Date dengan format YYYY-MM-DD\n",
    "        df['Date'] = df['Timestamp'].dt.date\n",
    "        \n",
    "        # Tambah kolom tahun, bulan (angka), dan hari\n",
    "        df['Year'] = df['Timestamp'].dt.year\n",
    "        \n",
    "        # Buat kolom Month dengan nama bulan (Januari, Februari, dst)\n",
    "        bulan_indonesia = {\n",
    "            1: 'Januari', 2: 'Februari', 3: 'Maret', 4: 'April',\n",
    "            5: 'Mei', 6: 'Juni', 7: 'Juli', 8: 'Agustus',\n",
    "            9: 'September', 10: 'Oktober', 11: 'November', 12: 'Desember'\n",
    "        }\n",
    "        df['Month'] = df['Timestamp'].dt.month.map(bulan_indonesia)\n",
    "        \n",
    "        # Tambah kolom Day\n",
    "        df['Day'] = df['Timestamp'].dt.day\n",
    "        \n",
    "        # Hapus kolom Timestamp original\n",
    "        df.drop('Timestamp', axis=1, inplace=True)\n",
    "        \n",
    "        # Atur ulang urutan kolom\n",
    "        date_cols = ['Date', 'Year', 'Month', 'Day']\n",
    "        other_cols = [col for col in df.columns if col not in date_cols]\n",
    "        df = df[date_cols + other_cols]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ascii_to_excel(input_file, output_file=None):\n",
    "    \"\"\"\n",
    "    Mengkonversi file ASCII ke format Excel (.xlsx)\n",
    "    \n",
    "    Parameters:\n",
    "    input_file (str): Path ke file ASCII\n",
    "    output_file (str, optional): Path untuk menyimpan file Excel\n",
    "    \n",
    "    Returns:\n",
    "    str: Path ke file Excel yang dihasilkan\n",
    "    \"\"\"\n",
    "    # Gunakan fungsi convert_ascii_to_csv yang sudah ada untuk mendapatkan DataFrame\n",
    "    csv_file = convert_ascii_to_csv(input_file, output_file)\n",
    "    \n",
    "    if csv_file:\n",
    "        # Baca CSV yang baru dibuat\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Proses kolom tanggal\n",
    "        df = process_date_columns(df)\n",
    "        \n",
    "        # Simpan kembali ke CSV dengan format baru\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"✅ Berhasil memperbarui CSV dengan format tanggal baru: {csv_file}\")\n",
    "        \n",
    "        # Simpan ke Excel\n",
    "        excel_file = save_to_excel(df, csv_file)\n",
    "        return excel_file\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_files_with_excel(input_directory, output_directory=None, file_pattern='*.ascii'):\n",
    "    \"\"\"\n",
    "    Memproses banyak file ASCII dalam satu direktori dan menghasilkan file CSV dan Excel.\n",
    "    \n",
    "    Parameters:\n",
    "    input_directory (str): Path ke direktori yang berisi file ASCII\n",
    "    output_directory (str, optional): Path direktori untuk menyimpan file hasil\n",
    "    file_pattern (str, optional): Pola file yang akan diproses (default: *.ascii)\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (list of CSV files, list of Excel files)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_directory):\n",
    "        print(f\"❌ Direktori tidak ditemukan: {input_directory}\")\n",
    "        return [], []\n",
    "    \n",
    "    # Buat output directory jika belum ada\n",
    "    if output_directory is None:\n",
    "        output_directory = os.path.join(input_directory, 'convert')\n",
    "    \n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    print(f\"📁 Menggunakan direktori output: {output_directory}\")\n",
    "    \n",
    "    processed_csv_files = []\n",
    "    processed_excel_files = []\n",
    "    \n",
    "    # Cari semua file yang sesuai pola\n",
    "    for input_file in glob.glob(os.path.join(input_directory, file_pattern)):\n",
    "        filename = os.path.basename(input_file)\n",
    "        base_output = os.path.join(output_directory, os.path.splitext(filename)[0])\n",
    "        \n",
    "        print(f\"\\n🔄 Memproses {filename}...\")\n",
    "        try:\n",
    "            # Konversi ke CSV dan Excel dengan format tanggal baru\n",
    "            excel_file = convert_ascii_to_excel(input_file, base_output + '.csv')\n",
    "            if excel_file:\n",
    "                processed_excel_files.append(excel_file)\n",
    "                processed_csv_files.append(base_output + '.csv')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error saat memproses {filename}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\n✅ Selesai memproses {len(processed_csv_files)} file CSV dan {len(processed_excel_files)} file Excel\")\n",
    "    return processed_csv_files, processed_excel_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Menggunakan direktori output: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert\n",
      "\n",
      "🔄 Memproses rad4n90e_dy.ascii...\n",
      "📋 Terdeteksi format umum dari /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/rad4n90e_dy.ascii\n",
      "Kolom yang berhasil diproses: ['YYYYMMDD', 'HHMM', 'SWRad', 'StDev', 'Max', 'Q', 'S']\n",
      "Jumlah baris data: 1826\n",
      "✅ Berhasil menyimpan 1826 baris data ke /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/rad4n90e_dy.csv\n",
      "Total Baris Hilang per Kolom:\n",
      "\n",
      "                        Jumlah Missing Values\n",
      "SWRad                                       3\n",
      "StDev                                       2\n",
      "Max                                        10\n",
      "Q                                           0\n",
      "S                                           0\n",
      "Timestamp                                   0\n",
      "Total Data yang hilang                     15\n",
      "✅ Berhasil memperbarui CSV dengan format tanggal baru: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/rad4n90e_dy.csv\n",
      "✅ Berhasil menyimpan ke Excel: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/rad4n90e_dy.xlsx\n",
      "\n",
      "🔄 Memproses rain4n90e_dy.ascii...\n",
      "📋 Terdeteksi format umum dari /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/rain4n90e_dy.ascii\n",
      "Kolom yang berhasil diproses: ['YYYYMMDD', 'HHMM', 'Prec', 'StDev', '%Time', 'Q', 'S']\n",
      "Jumlah baris data: 1908\n",
      "✅ Berhasil menyimpan 1908 baris data ke /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/rain4n90e_dy.csv\n",
      "Total Baris Hilang per Kolom:\n",
      "\n",
      "                        Jumlah Missing Values\n",
      "Prec                                       40\n",
      "StDev                                       4\n",
      "%Time                                       4\n",
      "Q                                           0\n",
      "S                                           0\n",
      "Timestamp                                   0\n",
      "Total Data yang hilang                     48\n",
      "✅ Berhasil memperbarui CSV dengan format tanggal baru: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/rain4n90e_dy.csv\n",
      "✅ Berhasil menyimpan ke Excel: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/rain4n90e_dy.xlsx\n",
      "\n",
      "🔄 Memproses rh4n90e_dy.ascii...\n",
      "📋 Terdeteksi format umum dari /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/rh4n90e_dy.ascii\n",
      "Kolom yang berhasil diproses: ['YYYYMMDD', 'HHMM', 'RH', 'Q', 'S']\n",
      "Jumlah baris data: 1852\n",
      "✅ Berhasil menyimpan 1852 baris data ke /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/rh4n90e_dy.csv\n",
      "Total Baris Hilang per Kolom:\n",
      "\n",
      "                        Jumlah Missing Values\n",
      "RH                                          4\n",
      "Q                                           0\n",
      "S                                           0\n",
      "Timestamp                                   0\n",
      "Total Data yang hilang                      4\n",
      "✅ Berhasil memperbarui CSV dengan format tanggal baru: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/rh4n90e_dy.csv\n",
      "✅ Berhasil menyimpan ke Excel: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/rh4n90e_dy.xlsx\n",
      "\n",
      "🔄 Memproses sst4n90e_dy.ascii...\n",
      "📋 Terdeteksi format umum dari /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/sst4n90e_dy.ascii\n",
      "Kolom yang berhasil diproses: ['YYYYMMDD', 'HHMM', 'SST', 'Q', 'S']\n",
      "Jumlah baris data: 2397\n",
      "✅ Berhasil menyimpan 2397 baris data ke /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/sst4n90e_dy.csv\n",
      "Total Baris Hilang per Kolom:\n",
      "\n",
      "                        Jumlah Missing Values\n",
      "SST                                        40\n",
      "Q                                           0\n",
      "S                                           0\n",
      "Timestamp                                   0\n",
      "Total Data yang hilang                     40\n",
      "✅ Berhasil memperbarui CSV dengan format tanggal baru: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/sst4n90e_dy.csv\n",
      "✅ Berhasil menyimpan ke Excel: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/sst4n90e_dy.xlsx\n",
      "\n",
      "🔄 Memproses t4n90e_dy.ascii...\n",
      "📊 Terdeteksi format suhu (multi-kedalaman) dari /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/t4n90e_dy.ascii\n",
      "Kolom yang berhasil diproses: ['YYYYMMDD', 'HHMM', 'SST', 'TEMP_10.0m', 'TEMP_13.0m', 'TEMP_20.0m', 'TEMP_40.0m', 'TEMP_60.0m', 'TEMP_80.0m', 'TEMP_100.0m', 'TEMP_120.0m', 'TEMP_140.0m', 'TEMP_180.0m', 'TEMP_300.0m', 'TEMP_500.0m']\n",
      "Jumlah baris data: 3577\n",
      "✅ Berhasil menyimpan 3577 baris data ke /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/t4n90e_dy.csv\n",
      "✅ Berhasil memperbarui CSV dengan format tanggal baru: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/t4n90e_dy.csv\n",
      "✅ Berhasil menyimpan ke Excel: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/t4n90e_dy.xlsx\n",
      "\n",
      "🔄 Memproses w4n90e_dy.ascii...\n",
      "🌬️ Terdeteksi format angin dari /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/w4n90e_dy.ascii\n",
      "Kolom yang berhasil diproses: ['YYYYMMDD', 'HHMM', 'UWND', 'VWND', 'WSPD', 'WDIR']\n",
      "Jumlah baris data: 813\n",
      "✅ Berhasil menyimpan 813 baris data ke /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/w4n90e_dy.csv\n",
      "Total Baris Hilang per Kolom:\n",
      "\n",
      "                        Jumlah Missing Values\n",
      "UWND                                      217\n",
      "VWND                                      205\n",
      "WSPD                                        0\n",
      "WDIR                                        0\n",
      "Timestamp                                   0\n",
      "Total Data yang hilang                    422\n",
      "✅ Berhasil memperbarui CSV dengan format tanggal baru: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/w4n90e_dy.csv\n",
      "✅ Berhasil menyimpan ke Excel: /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/ASCII/convert/w4n90e_dy.xlsx\n",
      "\n",
      "✅ Selesai memproses 6 file CSV dan 6 file Excel\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Untuk single file\n",
    "    # convert_ascii_to_excel('/path/to/your/file.ascii')\n",
    "    \n",
    "    # Untuk banyak file\n",
    "    csv_files, excel_files = process_multiple_files_with_excel('/run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tugas-akhir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
