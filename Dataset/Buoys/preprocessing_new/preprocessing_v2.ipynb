{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_combine_buoy_data(location_code, data_dir):\n",
    "    \"\"\"\n",
    "    Load and combine all buoy data files for a specific location.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    location_code : str\n",
    "        Location identifier (e.g., '0N90E')\n",
    "    data_dir : str\n",
    "        Directory containing the data files\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing DataFrames for each variable type\n",
    "    \"\"\"\n",
    "    print(f\"Loading data for buoy location {location_code}...\")\n",
    "    \n",
    "    # Define variable types and their corresponding filenames\n",
    "    var_types = {\n",
    "        'radiation': f'rad{location_code.lower()}',\n",
    "        'rainfall': f'rain{location_code.lower()}',\n",
    "        'humidity': f'rh{location_code.lower()}',\n",
    "        'sst': f'sst{location_code.lower()}',\n",
    "        'temperature': f't{location_code.lower()}',\n",
    "        'wind': f'w{location_code.lower()}'\n",
    "    }\n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    # Load each variable type\n",
    "    for var_type, file_prefix in var_types.items():\n",
    "        # Look for matching files (could be .csv, .txt, etc.)\n",
    "        file_pattern = os.path.join(data_dir, f\"{file_prefix}*\")\n",
    "        matching_files = glob.glob(file_pattern)\n",
    "        \n",
    "        if matching_files:\n",
    "            file_path = matching_files[0]\n",
    "            try:\n",
    "                # Load the file\n",
    "                df = pd.read_csv(file_path)\n",
    "                print(f\"Successfully loaded {var_type} data from {file_path}\")\n",
    "                \n",
    "                # Convert date column to datetime\n",
    "                if 'Date' in df.columns:\n",
    "                    df['Date'] = pd.to_datetime(df['Date'])\n",
    "                    df.set_index('Date', inplace=True)\n",
    "                \n",
    "                # Store in dictionary\n",
    "                data_dict[var_type] = df\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {var_type} data: {e}\")\n",
    "        else:\n",
    "            print(f\"No {var_type} data file found matching pattern: {file_pattern}\")\n",
    "    \n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_quality_filtering(df, variable_type):\n",
    "    \"\"\"\n",
    "    Filter data based on quality codes (Q) and source codes (S).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        DataFrame containing the data\n",
    "    variable_type : str\n",
    "        Type of variable (for logging purposes)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Filtered DataFrame\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return df\n",
    "    \n",
    "    original_length = len(df)\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_filtered = df.copy()\n",
    "    \n",
    "    # Filter based on quality codes\n",
    "    if 'Q' in df_filtered.columns:\n",
    "        # Create a boolean mask for quality filtering\n",
    "        # Q=0: Missing data - remove\n",
    "        # Q=1: Highest quality - keep\n",
    "        # Q=2: Default quality - keep\n",
    "        # Q=3: Adjusted data - keep but flag\n",
    "        # Q=4: Lower quality - keep but flag\n",
    "        # Q=5: Sensor failed - remove\n",
    "        \n",
    "        # Remove missing data and failed sensors\n",
    "        quality_mask = (df_filtered['Q'] > 0) & (df_filtered['Q'] < 5)\n",
    "        df_filtered = df_filtered[quality_mask].copy()\n",
    "        \n",
    "        # Add flag for adjusted data and lower quality\n",
    "        if 'data_quality' not in df_filtered.columns:\n",
    "            df_filtered['data_quality'] = 'high'\n",
    "        \n",
    "        # Mark adjusted data\n",
    "        if 'Q' in df_filtered.columns:\n",
    "            df_filtered.loc[df_filtered['Q'] == 3, 'data_quality'] = 'adjusted'\n",
    "            df_filtered.loc[df_filtered['Q'] == 4, 'data_quality'] = 'low'\n",
    "        \n",
    "        quality_filtered_length = len(df_filtered)\n",
    "        print(f\"Quality filtering for {variable_type}: Kept {quality_filtered_length}/{original_length} rows ({quality_filtered_length/original_length*100:.2f}%)\")\n",
    "    \n",
    "    # Filter based on source codes\n",
    "    # Focus on source codes 5 (Recovered from Instrument RAM) as it seems to be the most common and reliable\n",
    "    if 'S' in df_filtered.columns:\n",
    "        # Prioritize data from RAM (delayed mode) over telemetry\n",
    "        df_filtered['source_priority'] = 1  # Default priority\n",
    "        df_filtered.loc[df_filtered['S'] == 5, 'source_priority'] = 5  # Recovered from RAM (highest)\n",
    "        df_filtered.loc[df_filtered['S'] == 6, 'source_priority'] = 4  # Derived from RAM\n",
    "        df_filtered.loc[df_filtered['S'] == 7, 'source_priority'] = 3  # Temporally interpolated from RAM\n",
    "        df_filtered.loc[df_filtered['S'] == 8, 'source_priority'] = 2  # Spatially interpolated from RAM\n",
    "        \n",
    "        # Keep this information for reference but don't filter based on source yet\n",
    "        # We'll use it when merging/combining data sources\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, variable_type, variables=None):\n",
    "    \"\"\"\n",
    "    Handle missing values using appropriate strategies for each variable type.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        DataFrame containing the data\n",
    "    variable_type : str\n",
    "        Type of variable ('radiation', 'rainfall', etc.)\n",
    "    variables : list\n",
    "        List of specific variables to process (optional)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        DataFrame with imputed values\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return df\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_imputed = df.copy()\n",
    "    \n",
    "    # Get the variables to process\n",
    "    if variables is None:\n",
    "        # Process all numeric columns except Q and S\n",
    "        variables = [col for col in df_imputed.columns if col not in ['Q', 'S', 'data_quality', 'source_priority'] \n",
    "                    and pd.api.types.is_numeric_dtype(df_imputed[col])]\n",
    "    \n",
    "    print(f\"Handling missing values for {variable_type} variables: {variables}\")\n",
    "    \n",
    "    # Apply specific imputation strategies based on variable type\n",
    "    if variable_type == 'radiation':\n",
    "        # For radiation data (SWRad, StDev, Max) - use time-based interpolation\n",
    "        for var in variables:\n",
    "            missing_count = df_imputed[var].isna().sum()\n",
    "            if missing_count > 0:\n",
    "                print(f\"  Imputing {missing_count} missing values for {var}\")\n",
    "                \n",
    "                # First try time-based interpolation (for short gaps)\n",
    "                df_imputed[var] = df_imputed[var].interpolate(method='time', limit=3)\n",
    "                \n",
    "                # For remaining gaps, use forward fill with a limit\n",
    "                remaining_missing = df_imputed[var].isna().sum()\n",
    "                if remaining_missing > 0:\n",
    "                    df_imputed[var] = df_imputed[var].fillna(method='ffill', limit=2)\n",
    "                    \n",
    "                # Calculate how many were filled\n",
    "                final_missing = df_imputed[var].isna().sum()\n",
    "                filled_count = missing_count - final_missing\n",
    "                print(f\"    Filled {filled_count}/{missing_count} values. {final_missing} remain missing.\")\n",
    "    \n",
    "    elif variable_type == 'rainfall':\n",
    "        # For rainfall (Prec) - missing values often mean no rain\n",
    "        for var in variables:\n",
    "            if var == 'Prec':\n",
    "                missing_count = df_imputed[var].isna().sum()\n",
    "                if missing_count > 0:\n",
    "                    print(f\"  Imputing {missing_count} missing values for {var} with zeros\")\n",
    "                    df_imputed[var] = df_imputed[var].fillna(0)\n",
    "            else:\n",
    "                # For other rainfall-related variables (StDev, %Time)\n",
    "                missing_count = df_imputed[var].isna().sum()\n",
    "                if missing_count > 0:\n",
    "                    print(f\"  Imputing {missing_count} missing values for {var}\")\n",
    "                    df_imputed[var] = df_imputed[var].interpolate(method='linear', limit=2)\n",
    "    \n",
    "    elif variable_type == 'humidity':\n",
    "        # For humidity (RH) - tends to be stable, use ffill+bfill\n",
    "        for var in variables:\n",
    "            missing_count = df_imputed[var].isna().sum()\n",
    "            if missing_count > 0:\n",
    "                print(f\"  Imputing {missing_count} missing values for {var}\")\n",
    "                df_imputed[var] = df_imputed[var].fillna(method='ffill', limit=2)\n",
    "                remaining_missing = df_imputed[var].isna().sum()\n",
    "                if remaining_missing > 0:\n",
    "                    df_imputed[var] = df_imputed[var].fillna(method='bfill', limit=2)\n",
    "                final_missing = df_imputed[var].isna().sum()\n",
    "                filled_count = missing_count - final_missing\n",
    "                print(f\"    Filled {filled_count}/{missing_count} values. {final_missing} remain missing.\")\n",
    "    \n",
    "    elif variable_type in ['sst', 'temperature']:\n",
    "        # For temperature data - linear interpolation in both directions\n",
    "        for var in variables:\n",
    "            missing_count = df_imputed[var].isna().sum()\n",
    "            if missing_count > 0:\n",
    "                print(f\"  Imputing {missing_count} missing values for {var}\")\n",
    "                df_imputed[var] = df_imputed[var].interpolate(method='linear', limit_direction='both', limit=3)\n",
    "                final_missing = df_imputed[var].isna().sum()\n",
    "                filled_count = missing_count - final_missing\n",
    "                print(f\"    Filled {filled_count}/{missing_count} values. {final_missing} remain missing.\")\n",
    "    \n",
    "    elif variable_type == 'wind':\n",
    "        # For wind data - linear interpolation\n",
    "        for var in variables:\n",
    "            missing_count = df_imputed[var].isna().sum()\n",
    "            if missing_count > 0:\n",
    "                print(f\"  Imputing {missing_count} missing values for {var}\")\n",
    "                df_imputed[var] = df_imputed[var].interpolate(method='linear', limit_direction='both', limit=2)\n",
    "                final_missing = df_imputed[var].isna().sum()\n",
    "                filled_count = missing_count - final_missing\n",
    "                print(f\"    Filled {filled_count}/{missing_count} values. {final_missing} remain missing.\")\n",
    "    \n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_buoy_data(data_dict, location_code, output_dir=\"output\", cleaned_dir=\"cleaned\"):\n",
    "    \"\"\"\n",
    "    Preprocess all buoy data variables.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary containing DataFrames for each variable type\n",
    "    location_code : str\n",
    "        Location identifier (e.g., '0N90E')\n",
    "    output_dir : str\n",
    "        Directory for saving visualization outputs\n",
    "    cleaned_dir : str\n",
    "        Directory for saving cleaned data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing cleaned DataFrames\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(cleaned_dir, exist_ok=True)\n",
    "    loc_output_dir = os.path.join(output_dir, location_code)\n",
    "    os.makedirs(loc_output_dir, exist_ok=True)\n",
    "    \n",
    "    cleaned_data = {}\n",
    "    \n",
    "    # Process radiation data\n",
    "    if 'radiation' in data_dict:\n",
    "        print(\"\\nProcessing Short Wave Radiation data...\")\n",
    "        df_rad = data_dict['radiation'].copy()\n",
    "        \n",
    "        # Apply quality filtering\n",
    "        df_rad_filtered = apply_quality_filtering(df_rad, \"radiation\")\n",
    "        \n",
    "        # Apply missing value handling\n",
    "        df_rad_clean = handle_missing_values(df_rad_filtered, \"radiation\", ['SWRad', 'StDev', 'Max'])\n",
    "        \n",
    "        # Process SWRad variable\n",
    "        if 'SWRad' in df_rad_clean.columns:\n",
    "            # Handle outliers\n",
    "            df_rad_clean = handle_outliers(df_rad_clean, 'SWRad')\n",
    "            \n",
    "            # Visualize\n",
    "            plot_time_series(df_rad_clean, 'SWRad', 'Short Wave Radiation', 'W/m²', location_code, loc_output_dir)\n",
    "            plot_seasonal_patterns(df_rad_clean, 'SWRad', 'Short Wave Radiation', 'W/m²', location_code, loc_output_dir)\n",
    "            plot_annual_trends(df_rad_clean, 'SWRad', 'Short Wave Radiation', 'W/m²', location_code, loc_output_dir)\n",
    "            \n",
    "            # Store cleaned data\n",
    "            cleaned_data['SWRad'] = df_rad_clean[['SWRad']].copy()\n",
    "            \n",
    "            # Save to CSV\n",
    "            df_rad_clean.to_csv(f\"{cleaned_dir}/{location_code}_SWRad_clean.csv\")\n",
    "            print(f\"Saved cleaned radiation data to {cleaned_dir}/{location_code}_SWRad_clean.csv\")\n",
    "    \n",
    "    # Process rainfall data\n",
    "    if 'rainfall' in data_dict:\n",
    "        print(\"\\nProcessing Rainfall data...\")\n",
    "        df_rain = data_dict['rainfall'].copy()\n",
    "        \n",
    "        # Apply quality filtering\n",
    "        df_rain_filtered = apply_quality_filtering(df_rain, \"rainfall\")\n",
    "        \n",
    "        # Apply missing value handling\n",
    "        df_rain_clean = handle_missing_values(df_rain_filtered, \"rainfall\", ['Prec', 'StDev', '%Time'])\n",
    "        \n",
    "        # Process Prec variable\n",
    "        if 'Prec' in df_rain_clean.columns:\n",
    "            # Handle outliers\n",
    "            df_rain_clean = handle_outliers(df_rain_clean, 'Prec')\n",
    "            \n",
    "            # Visualize\n",
    "            plot_time_series(df_rain_clean, 'Prec', 'Rainfall', 'mm', location_code, loc_output_dir)\n",
    "            plot_seasonal_patterns(df_rain_clean, 'Prec', 'Rainfall', 'mm', location_code, loc_output_dir)\n",
    "            plot_annual_trends(df_rain_clean, 'Prec', 'Rainfall', 'mm', location_code, loc_output_dir)\n",
    "            \n",
    "            # Store cleaned data\n",
    "            cleaned_data['Prec'] = df_rain_clean[['Prec']].copy()\n",
    "            \n",
    "            # Save to CSV\n",
    "            df_rain_clean.to_csv(f\"{cleaned_dir}/{location_code}_Prec_clean.csv\")\n",
    "            print(f\"Saved cleaned rainfall data to {cleaned_dir}/{location_code}_Prec_clean.csv\")\n",
    "    \n",
    "    # Process humidity data\n",
    "    if 'humidity' in data_dict:\n",
    "        print(\"\\nProcessing Relative Humidity data...\")\n",
    "        df_rh = data_dict['humidity'].copy()\n",
    "        \n",
    "        # Apply quality filtering\n",
    "        df_rh_filtered = apply_quality_filtering(df_rh, \"humidity\")\n",
    "        \n",
    "        # Apply missing value handling\n",
    "        df_rh_clean = handle_missing_values(df_rh_filtered, \"humidity\", ['RH'])\n",
    "        \n",
    "        # Process RH variable\n",
    "        if 'RH' in df_rh_clean.columns:\n",
    "            # Handle outliers\n",
    "            df_rh_clean = handle_outliers(df_rh_clean, 'RH')\n",
    "            \n",
    "            # Visualize\n",
    "            plot_time_series(df_rh_clean, 'RH', 'Relative Humidity', '%', location_code, loc_output_dir)\n",
    "            plot_seasonal_patterns(df_rh_clean, 'RH', 'Relative Humidity', '%', location_code, loc_output_dir)\n",
    "            plot_annual_trends(df_rh_clean, 'RH', 'Relative Humidity', '%', location_code, loc_output_dir)\n",
    "            \n",
    "            # Store cleaned data\n",
    "            cleaned_data['RH'] = df_rh_clean[['RH']].copy()\n",
    "            \n",
    "            # Save to CSV\n",
    "            df_rh_clean.to_csv(f\"{cleaned_dir}/{location_code}_RH_clean.csv\")\n",
    "            print(f\"Saved cleaned humidity data to {cleaned_dir}/{location_code}_RH_clean.csv\")\n",
    "    \n",
    "    # Process SST data - prioritize sst0n90e.csv over t0n90e.csv for SST\n",
    "    if 'sst' in data_dict:\n",
    "        print(\"\\nProcessing Sea Surface Temperature data...\")\n",
    "        df_sst = data_dict['sst'].copy()\n",
    "        \n",
    "        # Apply quality filtering\n",
    "        df_sst_filtered = apply_quality_filtering(df_sst, \"sst\")\n",
    "        \n",
    "        # Apply missing value handling\n",
    "        df_sst_clean = handle_missing_values(df_sst_filtered, \"sst\", ['SST'])\n",
    "        \n",
    "        # Process SST variable\n",
    "        if 'SST' in df_sst_clean.columns:\n",
    "            # Handle outliers\n",
    "            df_sst_clean = handle_outliers(df_sst_clean, 'SST')\n",
    "            \n",
    "            # Visualize\n",
    "            plot_time_series(df_sst_clean, 'SST', 'Sea Surface Temperature', '°C', location_code, loc_output_dir)\n",
    "            plot_seasonal_patterns(df_sst_clean, 'SST', 'Sea Surface Temperature', '°C', location_code, loc_output_dir)\n",
    "            plot_annual_trends(df_sst_clean, 'SST', 'Sea Surface Temperature', '°C', location_code, loc_output_dir)\n",
    "            \n",
    "            # Store cleaned data\n",
    "            cleaned_data['SST'] = df_sst_clean[['SST']].copy()\n",
    "            \n",
    "            # Save to CSV\n",
    "            df_sst_clean.to_csv(f\"{cleaned_dir}/{location_code}_SST_clean.csv\")\n",
    "            print(f\"Saved cleaned SST data to {cleaned_dir}/{location_code}_SST_clean.csv\")\n",
    "    \n",
    "    # Process temperature profile data\n",
    "    if 'temperature' in data_dict:\n",
    "        print(\"\\nProcessing Temperature Profile data...\")\n",
    "        df_temp = data_dict['temperature'].copy()\n",
    "        \n",
    "        # Remove the SST column since we're using the one from sst0n90e.csv\n",
    "        if 'SST' in df_temp.columns and 'SST' in cleaned_data:\n",
    "            print(\"  Removing duplicate SST column from temperature profile data (using the one from SST data)\")\n",
    "            df_temp = df_temp.drop(columns=['SST'])\n",
    "        \n",
    "        # Find temperature columns (look for columns with 'TEMP' prefix)\n",
    "        temp_cols = [col for col in df_temp.columns if col.startswith('TEMP_')]\n",
    "        \n",
    "        if temp_cols:\n",
    "            print(f\"Found {len(temp_cols)} temperature depth measurements\")\n",
    "            \n",
    "            # Apply quality filtering (if quality columns exist)\n",
    "            df_temp_filtered = apply_quality_filtering(df_temp, \"temperature\")\n",
    "            \n",
    "            # Apply missing value handling for all temperature columns\n",
    "            df_temp_clean = handle_missing_values(df_temp_filtered, \"temperature\", temp_cols)\n",
    "            \n",
    "            # Process each depth\n",
    "            for col in temp_cols:\n",
    "                # Extract depth from column name\n",
    "                depth = col.split('_')[1].replace('m', '')\n",
    "                print(f\"Processing temperature at depth {depth}m\")\n",
    "                \n",
    "                if pd.api.types.is_numeric_dtype(df_temp_clean[col]):\n",
    "                    # Handle outliers\n",
    "                    df_temp_clean = handle_outliers(df_temp_clean, col)\n",
    "                    \n",
    "                    # Visualize\n",
    "                    plot_time_series(df_temp_clean, col, f'Water Temperature {depth}m', '°C', location_code, loc_output_dir)\n",
    "                    \n",
    "                    # Store cleaned data\n",
    "                    cleaned_data[f'TEMP_{depth}'] = df_temp_clean[[col]].copy()\n",
    "            \n",
    "            # Create a simplified dataframe with selected depths (if needed)\n",
    "            selected_depths = ['10.0m', '100.0m', '300.0m'] if len(temp_cols) > 3 else temp_cols\n",
    "            selected_cols = [f'TEMP_{depth}' for depth in selected_depths if f'TEMP_{depth}' in df_temp_clean.columns]\n",
    "            \n",
    "            if selected_cols:\n",
    "                # Plot temperature profiles\n",
    "                plot_temperature_profile(df_temp_clean, selected_cols, location_code, loc_output_dir)\n",
    "            \n",
    "            # Save to CSV\n",
    "            df_temp_clean.to_csv(f\"{cleaned_dir}/{location_code}_TEMP_clean.csv\")\n",
    "            print(f\"Saved cleaned temperature profile data to {cleaned_dir}/{location_code}_TEMP_clean.csv\")\n",
    "    \n",
    "    # Process wind data\n",
    "    if 'wind' in data_dict:\n",
    "        print(\"\\nProcessing Wind data...\")\n",
    "        df_wind = data_dict['wind'].copy()\n",
    "        \n",
    "        # Apply quality filtering\n",
    "        # Note: Wind data sometimes lacks Q and S columns\n",
    "        if 'Q' in df_wind.columns or 'S' in df_wind.columns:\n",
    "            df_wind_filtered = apply_quality_filtering(df_wind, \"wind\")\n",
    "        else:\n",
    "            print(\"  No quality or source columns found in wind data\")\n",
    "            df_wind_filtered = df_wind.copy()\n",
    "        \n",
    "        # Apply missing value handling\n",
    "        wind_cols = [col for col in ['UWND', 'VWND', 'WSPD', 'WDIR'] if col in df_wind_filtered.columns]\n",
    "        df_wind_clean = handle_missing_values(df_wind_filtered, \"wind\", wind_cols)\n",
    "        \n",
    "        # Process wind components\n",
    "        for col in wind_cols:\n",
    "            if col in df_wind_clean.columns:\n",
    "                # Handle outliers\n",
    "                df_wind_clean = handle_outliers(df_wind_clean, col)\n",
    "        \n",
    "        # Visualize wind speed\n",
    "        if 'WSPD' in df_wind_clean.columns:\n",
    "            plot_time_series(df_wind_clean, 'WSPD', 'Wind Speed', 'm/s', location_code, loc_output_dir)\n",
    "            plot_seasonal_patterns(df_wind_clean, 'WSPD', 'Wind Speed', 'm/s', location_code, loc_output_dir)\n",
    "            plot_annual_trends(df_wind_clean, 'WSPD', 'Wind Speed', 'm/s', location_code, loc_output_dir)\n",
    "            \n",
    "            # Store cleaned data\n",
    "            cleaned_data['WSPD'] = df_wind_clean[['WSPD']].copy()\n",
    "        \n",
    "        # Wind direction visualization (if both components available)\n",
    "        if 'UWND' in df_wind_clean.columns and 'VWND' in df_wind_clean.columns:\n",
    "            plot_wind_rose(df_wind_clean, location_code, loc_output_dir)\n",
    "        \n",
    "        # Save to CSV\n",
    "        df_wind_clean.to_csv(f\"{cleaned_dir}/{location_code}_WIND_clean.csv\")\n",
    "        print(f\"Saved cleaned wind data to {cleaned_dir}/{location_code}_WIND_clean.csv\")\n",
    "    \n",
    "    # Create a combined dataset with key variables\n",
    "    print(\"\\nCreating combined dataset...\")\n",
    "    combine_key_variables(cleaned_data, location_code, cleaned_dir)\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, variable, method='zscore', threshold=3):\n",
    "    \"\"\"Handle outliers in the specified variable.\"\"\"\n",
    "    df_result = df.copy()\n",
    "    \n",
    "    # Skip if variable doesn't exist or is non-numeric\n",
    "    if variable not in df_result.columns:\n",
    "        return df_result\n",
    "        \n",
    "    if not pd.api.types.is_numeric_dtype(df_result[variable]):\n",
    "        print(f\"Skipping outlier detection for non-numeric variable: {variable}\")\n",
    "        return df_result\n",
    "    \n",
    "    # Skip if too many NaN values\n",
    "    nan_count = df_result[variable].isna().sum()\n",
    "    if nan_count > len(df_result) * 0.5:\n",
    "        print(f\"Skipping outlier detection for {variable}: too many NaN values ({nan_count} / {len(df_result)})\")\n",
    "        return df_result\n",
    "    \n",
    "    # Get original count\n",
    "    valid_data = df_result[variable].dropna()\n",
    "    original_count = len(valid_data)\n",
    "    \n",
    "    if original_count == 0:\n",
    "        return df_result\n",
    "    \n",
    "    # Detect outliers\n",
    "    try:\n",
    "        if method == 'zscore':\n",
    "            z_scores = np.abs(stats.zscore(valid_data))\n",
    "            outliers = z_scores > threshold\n",
    "            outlier_indices = valid_data.index[outliers]\n",
    "        elif method == 'iqr':\n",
    "            Q1 = valid_data.quantile(0.25)\n",
    "            Q3 = valid_data.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "            outlier_indices = valid_data[(valid_data < lower_bound) | (valid_data > upper_bound)].index\n",
    "        else:\n",
    "            print(f\"Unknown outlier detection method: {method}\")\n",
    "            return df_result\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting outliers for {variable}: {e}\")\n",
    "        return df_result\n",
    "    \n",
    "    # Mark outliers\n",
    "    if len(outlier_indices) > 0:\n",
    "        print(f\"Detected {len(outlier_indices)} outliers in {variable} ({len(outlier_indices)/original_count*100:.2f}%)\")\n",
    "        \n",
    "        # Create an 'is_outlier_[var]' column\n",
    "        outlier_col = f\"is_outlier_{variable.replace('(', '').replace(')', '').replace('.', '_')}\"\n",
    "        df_result[outlier_col] = False\n",
    "        df_result.loc[outlier_indices, outlier_col] = True\n",
    "        \n",
    "        # For modeling preparation, we might want to replace outliers with NaN\n",
    "        # rather than removing them, so the time series structure is preserved\n",
    "        df_result.loc[outlier_indices, variable] = np.nan\n",
    "        \n",
    "        print(f\"Marked outliers in column '{outlier_col}' and replaced values with NaN\")\n",
    "    else:\n",
    "        print(f\"No outliers detected in {variable}\")\n",
    "    \n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(df, variable, var_name, unit, location_code, output_dir):\n",
    "    \"\"\"Plot time series for a variable.\"\"\"\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(df.index, df[variable], 'o-', alpha=0.5, markersize=2)\n",
    "    \n",
    "    plt.title(f'{var_name} at {location_code}')\n",
    "    plt.ylabel(f'{var_name} ({unit})')\n",
    "    plt.xlabel('Date')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Add a 30-day rolling average to show trend\n",
    "    if len(df) > 30:\n",
    "        valid_data = df[variable].dropna()\n",
    "        if len(valid_data) > 30:\n",
    "            rolling_avg = valid_data.rolling(window=30, center=True).mean()\n",
    "            plt.plot(valid_data.index, rolling_avg, 'r-', linewidth=2, label='30-day Rolling Average')\n",
    "            plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    var_file = variable.replace('(', '').replace(')', '').replace('.', '_')\n",
    "    plt.savefig(f'{output_dir}/{var_file}_time_series.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seasonal_patterns(df, variable, var_name, unit, location_code, output_dir):\n",
    "    \"\"\"Plot seasonal patterns for a variable.\"\"\"\n",
    "    # Skip if not enough data\n",
    "    if len(df) < 30:\n",
    "        print(f\"Skipping seasonal analysis for {variable}: insufficient data\")\n",
    "        return\n",
    "    \n",
    "    # Resample to monthly data\n",
    "    try:\n",
    "        monthly_data = df[variable].resample('M').mean()\n",
    "        \n",
    "        # Create month and year columns\n",
    "        monthly_df = pd.DataFrame(monthly_data)\n",
    "        monthly_df['month'] = monthly_df.index.month\n",
    "        monthly_df['year'] = monthly_df.index.year\n",
    "        \n",
    "        # Plot monthly patterns\n",
    "        monthly_pattern = monthly_df.groupby('month')[variable].mean()\n",
    "        months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        monthly_pattern.plot(kind='bar')\n",
    "        plt.title(f'Monthly {var_name} Pattern at {location_code}')\n",
    "        plt.ylabel(f'{var_name} ({unit})')\n",
    "        plt.xlabel('Month')\n",
    "        plt.xticks(np.arange(12), months, rotation=45)\n",
    "        plt.grid(True, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        var_file = variable.replace('(', '').replace(')', '').replace('.', '_')\n",
    "        plt.savefig(f'{output_dir}/{var_file}_monthly_pattern.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Boxplot of monthly values (showing variation within each month)\n",
    "        if len(monthly_df) >= 12:  # Only if we have enough data\n",
    "            plt.figure(figsize=(14, 6))\n",
    "            sns.boxplot(x='month', y=variable, data=monthly_df)\n",
    "            plt.title(f'Monthly {var_name} Distribution at {location_code}')\n",
    "            plt.ylabel(f'{var_name} ({unit})')\n",
    "            plt.xlabel('Month')\n",
    "            plt.xticks(np.arange(12), months, rotation=45)\n",
    "            plt.grid(True, axis='y')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_dir}/{var_file}_monthly_boxplot.png')\n",
    "            plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in seasonal analysis for {variable}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_annual_trends(df, variable, var_name, unit, location_code, output_dir):\n",
    "    \"\"\"Plot annual trends for a variable.\"\"\"\n",
    "    # Skip if not enough data\n",
    "    if len(df) < 365:\n",
    "        print(f\"Skipping annual trend analysis for {variable}: insufficient data\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Resample to annual data\n",
    "        annual_data = df[variable].resample('Y').mean()\n",
    "        \n",
    "        # Skip if we have too few years\n",
    "        if len(annual_data) < 3:\n",
    "            print(f\"Skipping annual trend analysis for {variable}: less than 3 years of data\")\n",
    "            return\n",
    "        \n",
    "        # Plot annual trend\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        annual_data.plot()\n",
    "        \n",
    "        plt.title(f'Annual {var_name} Trend at {location_code}')\n",
    "        plt.ylabel(f'{var_name} ({unit})')\n",
    "        plt.xlabel('Year')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Add trend line\n",
    "        years_numeric = np.arange(len(annual_data))\n",
    "        \n",
    "        # Only calculate trend if we have enough valid data points\n",
    "        valid_data = annual_data.dropna()\n",
    "        if len(valid_data) >= 3:\n",
    "            numeric_idx = np.arange(len(valid_data))\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(numeric_idx, valid_data)\n",
    "            \n",
    "            trend_line = intercept + slope * numeric_idx\n",
    "            plt.plot(valid_data.index, trend_line, 'r--', \n",
    "                    label=f'Trend: {slope:.4f} per year (p={p_value:.4f}, R²={r_value**2:.4f})')\n",
    "            plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        var_file = variable.replace('(', '').replace(')', '').replace('.', '_')\n",
    "        plt.savefig(f'{output_dir}/{var_file}_annual_trend.png')\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in annual trend analysis for {variable}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_temperature_profile(df, temp_cols, location_code, output_dir):\n",
    "    \"\"\"Plot temperature profile at different depths.\"\"\"\n",
    "    try:\n",
    "        # Get average temperature at each depth\n",
    "        avg_temps = df[temp_cols].mean()\n",
    "        depths = [float(col.split('_')[1].replace('m', '')) for col in temp_cols]\n",
    "        \n",
    "        # Plot temperature profile\n",
    "        plt.figure(figsize=(8, 10))\n",
    "        plt.plot(avg_temps, depths, 'o-', linewidth=2)\n",
    "        plt.title(f'Average Temperature Profile at {location_code}')\n",
    "        plt.xlabel('Temperature (°C)')\n",
    "        plt.ylabel('Depth (m)')\n",
    "        plt.grid(True)\n",
    "        plt.gca().invert_yaxis()  # Invert y-axis to show depth increasing downward\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/temperature_profile.png')\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting temperature profile: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wind_rose(df, location_code, output_dir):\n",
    "    \"\"\"Plot wind rose diagram using wind components.\"\"\"\n",
    "    try:\n",
    "        # Check if required libraries are installed\n",
    "        try:\n",
    "            from windrose import WindroseAxes\n",
    "        except ImportError:\n",
    "            print(\"windrose package not found. Skipping wind rose plot.\")\n",
    "            return\n",
    "            \n",
    "        # Skip if not enough data\n",
    "        if len(df) < 30:\n",
    "            print(\"Skipping wind rose plot: insufficient data\")\n",
    "            return\n",
    "            \n",
    "        # Calculate wind speed and direction if not available\n",
    "        if 'WSPD' not in df.columns or 'WDIR' not in df.columns:\n",
    "            if 'UWND' in df.columns and 'VWND' in df.columns:\n",
    "                # Calculate wind speed and direction from U and V components\n",
    "                uwnd = df['UWND'].values\n",
    "                vwnd = df['VWND'].values\n",
    "                \n",
    "                # Skip rows with missing values\n",
    "                mask = ~(np.isnan(uwnd) | np.isnan(vwnd))\n",
    "                uwnd = uwnd[mask]\n",
    "                vwnd = vwnd[mask]\n",
    "                \n",
    "                if len(uwnd) < 30:\n",
    "                    print(\"Skipping wind rose plot: insufficient valid data\")\n",
    "                    return\n",
    "                \n",
    "                wspd = np.sqrt(uwnd**2 + vwnd**2)\n",
    "                wdir = (270 - np.arctan2(vwnd, uwnd) * 180 / np.pi) % 360\n",
    "                \n",
    "                # Create temporary DataFrame with calculated values\n",
    "                temp_df = pd.DataFrame({\n",
    "                    'wspd': wspd,\n",
    "                    'wdir': wdir\n",
    "                })\n",
    "            else:\n",
    "                print(\"Skipping wind rose plot: required wind components not available\")\n",
    "                return\n",
    "        else:\n",
    "            # Use available wind speed and direction\n",
    "            wspd = df['WSPD'].dropna().values\n",
    "            wdir = df['WDIR'].dropna().values\n",
    "            \n",
    "            # Create temporary DataFrame with values\n",
    "            temp_df = pd.DataFrame({\n",
    "                'wspd': wspd,\n",
    "                'wdir': wdir\n",
    "            })\n",
    "        \n",
    "        # Create wind rose\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        ax = WindroseAxes.from_ax()\n",
    "        ax.bar(temp_df['wdir'], temp_df['wspd'], normed=True, opening=0.8, edgecolor='white')\n",
    "        ax.set_legend(title='Wind Speed (m/s)')\n",
    "        plt.title(f'Wind Rose at {location_code}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/wind_rose.png')\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating wind rose plot: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_key_variables(cleaned_data, location_code, cleaned_dir):\n",
    "    \"\"\"Combine key variables into a single dataset.\"\"\"\n",
    "    try:\n",
    "        # Get key variables\n",
    "        key_vars = ['SST', 'Prec', 'RH', 'WSPD', 'SWRad']\n",
    "        available_vars = [var for var in key_vars if var in cleaned_data]\n",
    "        \n",
    "        if len(available_vars) <= 1:\n",
    "            print(\"Not enough variables available to create combined dataset\")\n",
    "            return\n",
    "        \n",
    "        # Combine into single DataFrame\n",
    "        combined_df = pd.DataFrame()\n",
    "        \n",
    "        for var in available_vars:\n",
    "            if combined_df.empty:\n",
    "                combined_df = cleaned_data[var].copy()\n",
    "            else:\n",
    "                combined_df = combined_df.join(cleaned_data[var], how='outer')\n",
    "        \n",
    "        # Save combined dataset\n",
    "        combined_file = f\"{cleaned_dir}/{location_code}_combined_clean.csv\"\n",
    "        combined_df.to_csv(combined_file)\n",
    "        print(f\"Saved combined dataset with {len(available_vars)} variables to {combined_file}\")\n",
    "        \n",
    "        # Create correlation matrix if we have enough variables\n",
    "        if len(available_vars) >= 2:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            corr_matrix = combined_df.corr()\n",
    "            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "            plt.title(f'Correlation Matrix for {location_code}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{cleaned_dir}/{location_code}_correlation_matrix.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            print(\"Created correlation matrix visualization\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating combined dataset: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing run at 20250503_224547\n",
      "\n",
      "==================================================\n",
      "Processing location: 0N90E\n",
      "==================================================\n",
      "Loading data for buoy location 0N90E...\n",
      "Successfully loaded radiation data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/rad0n90e_dy.csv\n",
      "Successfully loaded rainfall data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/rain0n90e_dy.csv\n",
      "Successfully loaded humidity data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/rh0n90e_dy.csv\n",
      "Successfully loaded sst data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/sst0n90e_dy.csv\n",
      "Successfully loaded temperature data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/t0n90e_dy.csv\n",
      "Successfully loaded wind data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/w0n90e_dy.csv\n",
      "\n",
      "Processing Short Wave Radiation data...\n",
      "Quality filtering for radiation: Kept 3545/3559 rows (99.61%)\n",
      "Handling missing values for radiation variables: ['SWRad', 'StDev', 'Max']\n",
      "  Imputing 9 missing values for Max\n",
      "    Filled 9/9 values. 0 remain missing.\n",
      "No outliers detected in SWRad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned radiation data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/../CSV CLEANED/0N90E_SWRad_clean.csv\n",
      "\n",
      "Processing Rainfall data...\n",
      "Quality filtering for rainfall: Kept 3194/3275 rows (97.53%)\n",
      "Handling missing values for rainfall variables: ['Prec', 'StDev', '%Time']\n",
      "Detected 52 outliers in Prec (1.63%)\n",
      "Marked outliers in column 'is_outlier_Prec' and replaced values with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned rainfall data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/../CSV CLEANED/0N90E_Prec_clean.csv\n",
      "\n",
      "Processing Relative Humidity data...\n",
      "Quality filtering for humidity: Kept 3440/3446 rows (99.83%)\n",
      "Handling missing values for humidity variables: ['RH']\n",
      "Detected 12 outliers in RH (0.35%)\n",
      "Marked outliers in column 'is_outlier_RH' and replaced values with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned humidity data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/../CSV CLEANED/0N90E_RH_clean.csv\n",
      "\n",
      "Processing Sea Surface Temperature data...\n",
      "Quality filtering for sst: Kept 4192/4203 rows (99.74%)\n",
      "Handling missing values for sst variables: ['SST']\n",
      "Detected 8 outliers in SST (0.19%)\n",
      "Marked outliers in column 'is_outlier_SST' and replaced values with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned SST data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/../CSV CLEANED/0N90E_SST_clean.csv\n",
      "\n",
      "Processing Temperature Profile data...\n",
      "  Removing duplicate SST column from temperature profile data (using the one from SST data)\n",
      "Found 11 temperature depth measurements\n",
      "Handling missing values for temperature variables: ['TEMP_10.0m', 'TEMP_20.0m', 'TEMP_40.0m', 'TEMP_60.0m', 'TEMP_80.0m', 'TEMP_100.0m', 'TEMP_120.0m', 'TEMP_140.0m', 'TEMP_180.0m', 'TEMP_300.0m', 'TEMP_500.0m']\n",
      "  Imputing 708 missing values for TEMP_10.0m\n",
      "    Filled 60/708 values. 648 remain missing.\n",
      "  Imputing 117 missing values for TEMP_20.0m\n",
      "    Filled 78/117 values. 39 remain missing.\n",
      "  Imputing 976 missing values for TEMP_40.0m\n",
      "    Filled 71/976 values. 905 remain missing.\n",
      "  Imputing 774 missing values for TEMP_60.0m\n",
      "    Filled 61/774 values. 713 remain missing.\n",
      "  Imputing 1263 missing values for TEMP_80.0m\n",
      "    Filled 88/1263 values. 1175 remain missing.\n",
      "  Imputing 559 missing values for TEMP_100.0m\n",
      "    Filled 57/559 values. 502 remain missing.\n",
      "  Imputing 1028 missing values for TEMP_120.0m\n",
      "    Filled 77/1028 values. 951 remain missing.\n",
      "  Imputing 735 missing values for TEMP_140.0m\n",
      "    Filled 83/735 values. 652 remain missing.\n",
      "  Imputing 1428 missing values for TEMP_180.0m\n",
      "    Filled 98/1428 values. 1330 remain missing.\n",
      "  Imputing 1008 missing values for TEMP_300.0m\n",
      "    Filled 107/1008 values. 901 remain missing.\n",
      "  Imputing 677 missing values for TEMP_500.0m\n",
      "    Filled 72/677 values. 605 remain missing.\n",
      "Processing temperature at depth 10.0m\n",
      "Detected 9 outliers in TEMP_10.0m (0.24%)\n",
      "Marked outliers in column 'is_outlier_TEMP_10_0m' and replaced values with NaN\n",
      "Processing temperature at depth 20.0m\n",
      "Detected 13 outliers in TEMP_20.0m (0.30%)\n",
      "Marked outliers in column 'is_outlier_TEMP_20_0m' and replaced values with NaN\n",
      "Processing temperature at depth 40.0m\n",
      "Detected 18 outliers in TEMP_40.0m (0.51%)\n",
      "Marked outliers in column 'is_outlier_TEMP_40_0m' and replaced values with NaN\n",
      "Processing temperature at depth 60.0m\n",
      "Detected 73 outliers in TEMP_60.0m (1.98%)\n",
      "Marked outliers in column 'is_outlier_TEMP_60_0m' and replaced values with NaN\n",
      "Processing temperature at depth 80.0m\n",
      "Detected 101 outliers in TEMP_80.0m (3.13%)\n",
      "Marked outliers in column 'is_outlier_TEMP_80_0m' and replaced values with NaN\n",
      "Processing temperature at depth 100.0m\n",
      "Detected 44 outliers in TEMP_100.0m (1.13%)\n",
      "Marked outliers in column 'is_outlier_TEMP_100_0m' and replaced values with NaN\n",
      "Processing temperature at depth 120.0m\n",
      "No outliers detected in TEMP_120.0m\n",
      "Processing temperature at depth 140.0m\n",
      "No outliers detected in TEMP_140.0m\n",
      "Processing temperature at depth 180.0m\n",
      "Detected 91 outliers in TEMP_180.0m (2.96%)\n",
      "Marked outliers in column 'is_outlier_TEMP_180_0m' and replaced values with NaN\n",
      "Processing temperature at depth 300.0m\n",
      "Detected 13 outliers in TEMP_300.0m (0.37%)\n",
      "Marked outliers in column 'is_outlier_TEMP_300_0m' and replaced values with NaN\n",
      "Processing temperature at depth 500.0m\n",
      "Detected 46 outliers in TEMP_500.0m (1.21%)\n",
      "Marked outliers in column 'is_outlier_TEMP_500_0m' and replaced values with NaN\n",
      "Saved cleaned temperature profile data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/../CSV CLEANED/0N90E_TEMP_clean.csv\n",
      "\n",
      "Processing Wind data...\n",
      "  No quality or source columns found in wind data\n",
      "Handling missing values for wind variables: ['UWND', 'VWND', 'WSPD', 'WDIR']\n",
      "  Imputing 856 missing values for UWND\n",
      "    Filled 554/856 values. 302 remain missing.\n",
      "  Imputing 846 missing values for VWND\n",
      "    Filled 687/846 values. 159 remain missing.\n",
      "  Imputing 3 missing values for WSPD\n",
      "    Filled 3/3 values. 0 remain missing.\n",
      "  Imputing 3 missing values for WDIR\n",
      "    Filled 3/3 values. 0 remain missing.\n",
      "Detected 5 outliers in UWND (0.19%)\n",
      "Marked outliers in column 'is_outlier_UWND' and replaced values with NaN\n",
      "Detected 15 outliers in VWND (0.55%)\n",
      "Marked outliers in column 'is_outlier_VWND' and replaced values with NaN\n",
      "Detected 8 outliers in WSPD (0.28%)\n",
      "Marked outliers in column 'is_outlier_WSPD' and replaced values with NaN\n",
      "No outliers detected in WDIR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windrose package not found. Skipping wind rose plot.\n",
      "Saved cleaned wind data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/../CSV CLEANED/0N90E_WIND_clean.csv\n",
      "\n",
      "Creating combined dataset...\n",
      "Saved combined dataset with 5 variables to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV/../CSV CLEANED/0N90E_combined_clean.csv\n",
      "Created correlation matrix visualization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n",
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n",
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n",
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n",
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed data for location 0N90E\n",
      "\n",
      "==================================================\n",
      "Processing location: 4N90E\n",
      "==================================================\n",
      "Loading data for buoy location 4N90E...\n",
      "Successfully loaded radiation data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/rad4n90e_dy.csv\n",
      "Successfully loaded rainfall data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/rain4n90e_dy.csv\n",
      "Successfully loaded humidity data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/rh4n90e_dy.csv\n",
      "Successfully loaded sst data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/sst4n90e_dy.csv\n",
      "Successfully loaded temperature data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/t4n90e_dy.csv\n",
      "Successfully loaded wind data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/w4n90e_dy.csv\n",
      "\n",
      "Processing Short Wave Radiation data...\n",
      "Quality filtering for radiation: Kept 1823/1826 rows (99.84%)\n",
      "Handling missing values for radiation variables: ['SWRad', 'StDev', 'Max']\n",
      "  Imputing 8 missing values for Max\n",
      "    Filled 8/8 values. 0 remain missing.\n",
      "No outliers detected in SWRad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned radiation data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/../CSV CLEANED/4N90E_SWRad_clean.csv\n",
      "\n",
      "Processing Rainfall data...\n",
      "Quality filtering for rainfall: Kept 1868/1908 rows (97.90%)\n",
      "Handling missing values for rainfall variables: ['Prec', 'StDev', '%Time']\n",
      "Detected 35 outliers in Prec (1.87%)\n",
      "Marked outliers in column 'is_outlier_Prec' and replaced values with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned rainfall data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/../CSV CLEANED/4N90E_Prec_clean.csv\n",
      "\n",
      "Processing Relative Humidity data...\n",
      "Quality filtering for humidity: Kept 1848/1852 rows (99.78%)\n",
      "Handling missing values for humidity variables: ['RH']\n",
      "Detected 15 outliers in RH (0.81%)\n",
      "Marked outliers in column 'is_outlier_RH' and replaced values with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned humidity data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/../CSV CLEANED/4N90E_RH_clean.csv\n",
      "\n",
      "Processing Sea Surface Temperature data...\n",
      "Quality filtering for sst: Kept 2357/2397 rows (98.33%)\n",
      "Handling missing values for sst variables: ['SST']\n",
      "Detected 27 outliers in SST (1.15%)\n",
      "Marked outliers in column 'is_outlier_SST' and replaced values with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned SST data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/../CSV CLEANED/4N90E_SST_clean.csv\n",
      "\n",
      "Processing Temperature Profile data...\n",
      "  Removing duplicate SST column from temperature profile data (using the one from SST data)\n",
      "Found 12 temperature depth measurements\n",
      "Handling missing values for temperature variables: ['TEMP_10.0m', 'TEMP_13.0m', 'TEMP_20.0m', 'TEMP_40.0m', 'TEMP_60.0m', 'TEMP_80.0m', 'TEMP_100.0m', 'TEMP_120.0m', 'TEMP_140.0m', 'TEMP_180.0m', 'TEMP_300.0m', 'TEMP_500.0m']\n",
      "  Imputing 1821 missing values for TEMP_10.0m\n",
      "    Filled 50/1821 values. 1771 remain missing.\n",
      "  Imputing 998 missing values for TEMP_13.0m\n",
      "    Filled 39/998 values. 959 remain missing.\n",
      "  Imputing 1558 missing values for TEMP_20.0m\n",
      "    Filled 63/1558 values. 1495 remain missing.\n",
      "  Imputing 1041 missing values for TEMP_40.0m\n",
      "    Filled 54/1041 values. 987 remain missing.\n",
      "  Imputing 1656 missing values for TEMP_60.0m\n",
      "    Filled 68/1656 values. 1588 remain missing.\n",
      "  Imputing 1429 missing values for TEMP_80.0m\n",
      "    Filled 45/1429 values. 1384 remain missing.\n",
      "  Imputing 1080 missing values for TEMP_100.0m\n",
      "    Filled 65/1080 values. 1015 remain missing.\n",
      "  Imputing 282 missing values for TEMP_120.0m\n",
      "    Filled 51/282 values. 231 remain missing.\n",
      "  Imputing 130 missing values for TEMP_140.0m\n",
      "    Filled 40/130 values. 90 remain missing.\n",
      "  Imputing 128 missing values for TEMP_180.0m\n",
      "    Filled 38/128 values. 90 remain missing.\n",
      "  Imputing 838 missing values for TEMP_300.0m\n",
      "    Filled 43/838 values. 795 remain missing.\n",
      "  Imputing 839 missing values for TEMP_500.0m\n",
      "    Filled 44/839 values. 795 remain missing.\n",
      "Processing temperature at depth 10.0m\n",
      "Detected 3 outliers in TEMP_10.0m (0.17%)\n",
      "Marked outliers in column 'is_outlier_TEMP_10_0m' and replaced values with NaN\n",
      "Processing temperature at depth 13.0m\n",
      "Detected 24 outliers in TEMP_13.0m (0.92%)\n",
      "Marked outliers in column 'is_outlier_TEMP_13_0m' and replaced values with NaN\n",
      "Processing temperature at depth 20.0m\n",
      "No outliers detected in TEMP_20.0m\n",
      "Processing temperature at depth 40.0m\n",
      "Detected 27 outliers in TEMP_40.0m (1.04%)\n",
      "Marked outliers in column 'is_outlier_TEMP_40_0m' and replaced values with NaN\n",
      "Processing temperature at depth 60.0m\n",
      "Detected 62 outliers in TEMP_60.0m (3.12%)\n",
      "Marked outliers in column 'is_outlier_TEMP_60_0m' and replaced values with NaN\n",
      "Processing temperature at depth 80.0m\n",
      "Detected 1 outliers in TEMP_80.0m (0.05%)\n",
      "Marked outliers in column 'is_outlier_TEMP_80_0m' and replaced values with NaN\n",
      "Processing temperature at depth 100.0m\n",
      "No outliers detected in TEMP_100.0m\n",
      "Processing temperature at depth 120.0m\n",
      "Detected 7 outliers in TEMP_120.0m (0.21%)\n",
      "Marked outliers in column 'is_outlier_TEMP_120_0m' and replaced values with NaN\n",
      "Processing temperature at depth 140.0m\n",
      "Detected 51 outliers in TEMP_140.0m (1.46%)\n",
      "Marked outliers in column 'is_outlier_TEMP_140_0m' and replaced values with NaN\n",
      "Processing temperature at depth 180.0m\n",
      "Detected 63 outliers in TEMP_180.0m (1.81%)\n",
      "Marked outliers in column 'is_outlier_TEMP_180_0m' and replaced values with NaN\n",
      "Processing temperature at depth 300.0m\n",
      "Detected 27 outliers in TEMP_300.0m (0.97%)\n",
      "Marked outliers in column 'is_outlier_TEMP_300_0m' and replaced values with NaN\n",
      "Processing temperature at depth 500.0m\n",
      "Detected 32 outliers in TEMP_500.0m (1.15%)\n",
      "Marked outliers in column 'is_outlier_TEMP_500_0m' and replaced values with NaN\n",
      "Saved cleaned temperature profile data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/../CSV CLEANED/4N90E_TEMP_clean.csv\n",
      "\n",
      "Processing Wind data...\n",
      "  No quality or source columns found in wind data\n",
      "Handling missing values for wind variables: ['UWND', 'VWND', 'WSPD', 'WDIR']\n",
      "  Imputing 217 missing values for UWND\n",
      "    Filled 149/217 values. 68 remain missing.\n",
      "  Imputing 205 missing values for VWND\n",
      "    Filled 143/205 values. 62 remain missing.\n",
      "No outliers detected in UWND\n",
      "No outliers detected in VWND\n",
      "No outliers detected in WSPD\n",
      "No outliers detected in WDIR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windrose package not found. Skipping wind rose plot.\n",
      "Saved cleaned wind data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/../CSV CLEANED/4N90E_WIND_clean.csv\n",
      "\n",
      "Creating combined dataset...\n",
      "Saved combined dataset with 5 variables to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV/../CSV CLEANED/4N90E_combined_clean.csv\n",
      "Created correlation matrix visualization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n",
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n",
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n",
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n",
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed data for location 4N90E\n",
      "\n",
      "==================================================\n",
      "Processing location: 8N90E\n",
      "==================================================\n",
      "Loading data for buoy location 8N90E...\n",
      "Successfully loaded radiation data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/rad8n90e_dy.csv\n",
      "Successfully loaded rainfall data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/rain8n90e_dy.csv\n",
      "Successfully loaded humidity data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/rh8n90e_dy.csv\n",
      "Successfully loaded sst data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/sst8n90e_dy.csv\n",
      "Successfully loaded temperature data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/t8n90e_dy.csv\n",
      "Successfully loaded wind data from /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/w8n90e_dy.csv\n",
      "\n",
      "Processing Short Wave Radiation data...\n",
      "Quality filtering for radiation: Kept 3152/3166 rows (99.56%)\n",
      "Handling missing values for radiation variables: ['SWRad', 'StDev', 'Max']\n",
      "  Imputing 5 missing values for Max\n",
      "    Filled 5/5 values. 0 remain missing.\n",
      "Detected 10 outliers in SWRad (0.32%)\n",
      "Marked outliers in column 'is_outlier_SWRad' and replaced values with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned radiation data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/../CSV CLEANED/8N90E_SWRad_clean.csv\n",
      "\n",
      "Processing Rainfall data...\n",
      "Quality filtering for rainfall: Kept 1692/1713 rows (98.77%)\n",
      "Handling missing values for rainfall variables: ['Prec', 'StDev', '%Time']\n",
      "Detected 28 outliers in Prec (1.65%)\n",
      "Marked outliers in column 'is_outlier_Prec' and replaced values with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned rainfall data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/../CSV CLEANED/8N90E_Prec_clean.csv\n",
      "\n",
      "Processing Relative Humidity data...\n",
      "Quality filtering for humidity: Kept 3106/3113 rows (99.78%)\n",
      "Handling missing values for humidity variables: ['RH']\n",
      "Detected 30 outliers in RH (0.97%)\n",
      "Marked outliers in column 'is_outlier_RH' and replaced values with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned humidity data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/../CSV CLEANED/8N90E_RH_clean.csv\n",
      "\n",
      "Processing Sea Surface Temperature data...\n",
      "Quality filtering for sst: Kept 3006/3009 rows (99.90%)\n",
      "Handling missing values for sst variables: ['SST']\n",
      "Detected 42 outliers in SST (1.40%)\n",
      "Marked outliers in column 'is_outlier_SST' and replaced values with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned SST data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/../CSV CLEANED/8N90E_SST_clean.csv\n",
      "\n",
      "Processing Temperature Profile data...\n",
      "  Removing duplicate SST column from temperature profile data (using the one from SST data)\n",
      "Found 12 temperature depth measurements\n",
      "Handling missing values for temperature variables: ['TEMP_10.0m', 'TEMP_13.0m', 'TEMP_20.0m', 'TEMP_40.0m', 'TEMP_60.0m', 'TEMP_80.0m', 'TEMP_100.0m', 'TEMP_120.0m', 'TEMP_140.0m', 'TEMP_180.0m', 'TEMP_300.0m', 'TEMP_500.0m']\n",
      "  Imputing 728 missing values for TEMP_10.0m\n",
      "    Filled 48/728 values. 680 remain missing.\n",
      "  Imputing 581 missing values for TEMP_13.0m\n",
      "    Filled 49/581 values. 532 remain missing.\n",
      "  Imputing 644 missing values for TEMP_20.0m\n",
      "    Filled 60/644 values. 584 remain missing.\n",
      "  Imputing 560 missing values for TEMP_40.0m\n",
      "    Filled 51/560 values. 509 remain missing.\n",
      "  Imputing 510 missing values for TEMP_60.0m\n",
      "    Filled 50/510 values. 460 remain missing.\n",
      "  Imputing 472 missing values for TEMP_80.0m\n",
      "    Filled 48/472 values. 424 remain missing.\n",
      "  Imputing 193 missing values for TEMP_100.0m\n",
      "    Filled 48/193 values. 145 remain missing.\n",
      "  Imputing 468 missing values for TEMP_120.0m\n",
      "    Filled 73/468 values. 395 remain missing.\n",
      "  Imputing 115 missing values for TEMP_140.0m\n",
      "    Filled 44/115 values. 71 remain missing.\n",
      "  Imputing 471 missing values for TEMP_180.0m\n",
      "    Filled 54/471 values. 417 remain missing.\n",
      "  Imputing 112 missing values for TEMP_300.0m\n",
      "    Filled 43/112 values. 69 remain missing.\n",
      "  Imputing 838 missing values for TEMP_500.0m\n",
      "    Filled 40/838 values. 798 remain missing.\n",
      "Processing temperature at depth 10.0m\n",
      "Detected 33 outliers in TEMP_10.0m (1.15%)\n",
      "Marked outliers in column 'is_outlier_TEMP_10_0m' and replaced values with NaN\n",
      "Processing temperature at depth 13.0m\n",
      "Detected 40 outliers in TEMP_13.0m (1.32%)\n",
      "Marked outliers in column 'is_outlier_TEMP_13_0m' and replaced values with NaN\n",
      "Processing temperature at depth 20.0m\n",
      "Detected 21 outliers in TEMP_20.0m (0.71%)\n",
      "Marked outliers in column 'is_outlier_TEMP_20_0m' and replaced values with NaN\n",
      "Processing temperature at depth 40.0m\n",
      "Detected 45 outliers in TEMP_40.0m (1.48%)\n",
      "Marked outliers in column 'is_outlier_TEMP_40_0m' and replaced values with NaN\n",
      "Processing temperature at depth 60.0m\n",
      "Detected 25 outliers in TEMP_60.0m (0.81%)\n",
      "Marked outliers in column 'is_outlier_TEMP_60_0m' and replaced values with NaN\n",
      "Processing temperature at depth 80.0m\n",
      "Detected 1 outliers in TEMP_80.0m (0.03%)\n",
      "Marked outliers in column 'is_outlier_TEMP_80_0m' and replaced values with NaN\n",
      "Processing temperature at depth 100.0m\n",
      "No outliers detected in TEMP_100.0m\n",
      "Processing temperature at depth 120.0m\n",
      "Detected 3 outliers in TEMP_120.0m (0.09%)\n",
      "Marked outliers in column 'is_outlier_TEMP_120_0m' and replaced values with NaN\n",
      "Processing temperature at depth 140.0m\n",
      "Detected 4 outliers in TEMP_140.0m (0.11%)\n",
      "Marked outliers in column 'is_outlier_TEMP_140_0m' and replaced values with NaN\n",
      "Processing temperature at depth 180.0m\n",
      "No outliers detected in TEMP_180.0m\n",
      "Processing temperature at depth 300.0m\n",
      "No outliers detected in TEMP_300.0m\n",
      "Processing temperature at depth 500.0m\n",
      "Detected 11 outliers in TEMP_500.0m (0.40%)\n",
      "Marked outliers in column 'is_outlier_TEMP_500_0m' and replaced values with NaN\n",
      "Saved cleaned temperature profile data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/../CSV CLEANED/8N90E_TEMP_clean.csv\n",
      "\n",
      "Processing Wind data...\n",
      "  No quality or source columns found in wind data\n",
      "Handling missing values for wind variables: ['UWND', 'VWND', 'WSPD', 'WDIR']\n",
      "  Imputing 1472 missing values for UWND\n",
      "    Filled 307/1472 values. 1165 remain missing.\n",
      "  Imputing 1381 missing values for VWND\n",
      "    Filled 478/1381 values. 903 remain missing.\n",
      "  Imputing 5 missing values for WSPD\n",
      "    Filled 5/5 values. 0 remain missing.\n",
      "  Imputing 5 missing values for WDIR\n",
      "    Filled 5/5 values. 0 remain missing.\n",
      "Detected 1 outliers in UWND (0.05%)\n",
      "Marked outliers in column 'is_outlier_UWND' and replaced values with NaN\n",
      "No outliers detected in VWND\n",
      "No outliers detected in WSPD\n",
      "No outliers detected in WDIR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windrose package not found. Skipping wind rose plot.\n",
      "Saved cleaned wind data to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/../CSV CLEANED/8N90E_WIND_clean.csv\n",
      "\n",
      "Creating combined dataset...\n",
      "Saved combined dataset with 5 variables to /run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV/../CSV CLEANED/8N90E_combined_clean.csv\n",
      "Created correlation matrix visualization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n",
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n",
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n",
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n",
      "/tmp/ipykernel_16553/3129797877.py:10: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = df[variable].resample('M').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_data = df[variable].resample('Y').mean()\n",
      "/tmp/ipykernel_16553/721160045.py:36: UserWarning: This axis already has a converter set and is updating to a potentially incompatible converter\n",
      "  plt.plot(valid_data.index, trend_line, 'r--',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed data for location 8N90E\n",
      "\n",
      "Preprocessing run completed at 20250503_224640\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    # Define data directories for each location\n",
    "    data_dirs = {\n",
    "        '0N90E': '/run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/0N90E/CSV',\n",
    "        '4N90E': '/run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/4N90E/CSV',\n",
    "        '8N90E': '/run/media/cryptedlm/localdisk/Kuliah/Tugas Akhir/Dataset/Buoys/8N90E/CSV'\n",
    "    }\n",
    "    \n",
    "    # Define variable information (name and unit)\n",
    "    variable_info = {\n",
    "        'SST': ('Sea Surface Temperature', '°C'),\n",
    "        'RH': ('Relative Humidity', '%'),\n",
    "        'Prec': ('Rainfall', 'mm'),\n",
    "        'WSPD': ('Wind Speed', 'm/s'),\n",
    "        'SWRad': ('Short Wave Radiation', 'W/m²'),\n",
    "        'UWND': ('Zonal Wind', 'm/s'),\n",
    "        'VWND': ('Meridional Wind', 'm/s'),\n",
    "        'WDIR': ('Wind Direction', '°')\n",
    "        # Add other variables as needed\n",
    "    }\n",
    "    \n",
    "    # Define temperature columns for profile plotting\n",
    "    temp_cols = [\n",
    "        'TEMP_10.0m', 'TEMP_20.0m', 'TEMP_40.0m', 'TEMP_60.0m', 'TEMP_80.0m', \n",
    "        'TEMP_100.0m', 'TEMP_120.0m', 'TEMP_140.0m', 'TEMP_180.0m', \n",
    "        'TEMP_300.0m', 'TEMP_500.0m'\n",
    "    ]\n",
    "    \n",
    "    # Create timestamp for this preprocessing run\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    print(f\"Starting preprocessing run at {timestamp}\")\n",
    "    \n",
    "    # Process each location\n",
    "    for location, data_dir in data_dirs.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing location: {location}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Load data for the location\n",
    "        data_dict = load_and_combine_buoy_data(location, data_dir)\n",
    "        \n",
    "        # Skip if no data was loaded\n",
    "        if not data_dict:\n",
    "            print(f\"No data found for location {location}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Define output and cleaned directories for this location\n",
    "        output_dir = os.path.join(data_dir, \"../CSV CLEANED\")\n",
    "        cleaned_dir = os.path.join(data_dir, \"../CSV CLEANED\")\n",
    "        \n",
    "        # Ensure the directories exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        os.makedirs(cleaned_dir, exist_ok=True)\n",
    "        \n",
    "        # Preprocess the data\n",
    "        cleaned_data = preprocess_buoy_data(data_dict, location, output_dir, cleaned_dir)\n",
    "        \n",
    "        # Generate and save plots\n",
    "        for var_type, df in cleaned_data.items():\n",
    "            # Check if this DataFrame has variables we can plot\n",
    "            for variable in df.columns:\n",
    "                if variable in variable_info:\n",
    "                    var_name, unit = variable_info[variable]\n",
    "                    \n",
    "                    # Generate time series plot\n",
    "                    plot_time_series(df, variable, var_name, unit, location, output_dir)\n",
    "                    \n",
    "                    # Generate seasonal patterns plot\n",
    "                    plot_seasonal_patterns(df, variable, var_name, unit, location, output_dir)\n",
    "                    \n",
    "                    # Generate annual trends plot\n",
    "                    plot_annual_trends(df, variable, var_name, unit, location, output_dir)\n",
    "            \n",
    "            # Check if this is the temperature dataframe and has the needed columns\n",
    "            if all(col in df.columns for col in temp_cols):\n",
    "                plot_temperature_profile(df, temp_cols, location, output_dir)\n",
    "            \n",
    "            # Check if this is the wind dataframe with required columns\n",
    "            if all(col in df.columns for col in ['UWND', 'VWND', 'WDIR']):\n",
    "                plot_wind_rose(df, location, output_dir)\n",
    "        \n",
    "        # Check if preprocessing was successful\n",
    "        if cleaned_data:\n",
    "            print(f\"Successfully processed data for location {location}\")\n",
    "        else:\n",
    "            print(f\"Failed to process data for location {location}\")\n",
    "    \n",
    "    print(f\"\\nPreprocessing run completed at {datetime.now().strftime('%Y%m%d_%H%M%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tugas-akhir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
